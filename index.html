<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 8.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"let-ai.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.26.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js" defer></script>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3973904360441679"
     crossorigin="anonymous"></script>

    <meta name="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
<meta property="og:type" content="website">
<meta property="og:title" content="AI微小说">
<meta property="og:url" content="http://let-ai.com/index.html">
<meta property="og:site_name" content="AI微小说">
<meta property="og:description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="twoken">
<meta property="article:tag" content="openai,claude,modelscope,coze,微小说">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://let-ai.com/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>AI微小说 - 大模型写微小说</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-WJ48W3LM1R"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"G-WJ48W3LM1R","only_pageview":false,"measure_protocol_api_secret":null}</script>
  <script src="/js/third-party/analytics/google-analytics.js" defer></script>








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">AI微小说</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">大模型写微小说</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">twoken</p>
  <div class="site-description" itemprop="description">项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">11</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/twoken404" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;twoken404" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/twoken" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;twoken" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.facebook.com/twoken" title="FB Page → https:&#x2F;&#x2F;www.facebook.com&#x2F;twoken" rel="noopener me" target="_blank"><i class="fab fa-facebook fa-fw"></i>FB Page</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/e7084fd07ab0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/e7084fd07ab0/" class="post-title-link" itemprop="url">Conceptual Collapse  Visual Symbol Fixation in Text-to-Image Models for Abstract Concepts</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-12-13 11:57:13 / Modified: 12:24:04" itemprop="dateCreated datePublished" datetime="2025-12-13T11:57:13+08:00">2025-12-13</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>This study systematically investigates the visual symbol fixation phenomenon in multimodal generative models, particularly when processing abstract temporal concepts such as “nostalgia,” “memory,” and “past.” Through comprehensive evaluation of leading models including Gemini 3 Nano Banana Pro and Grok 4.1, we observe a recurring pattern where these systems default to high-frequency visual symbols (e.g., clocks, old photographs) when representing nuanced temporal abstractions. This “conceptual collapse” reveals fundamental limitations in cross-modal semantic mapping and highlights the tension between statistical pattern recognition and genuine conceptual understanding. Our analysis spans training data biases, architectural constraints, and practical implications for AI-assisted creativity.</p>
<p>Keywords:Multimodal AI, Conceptual Collapse, Visual Symbol Fixation, Abstract Representation, Text-to-Image Generation</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>The rapid evolution of multimodal AI systems has enabled sophisticated text-to-image generation capabilities across various models including <strong>Gemini 3 Nano Banana Pro</strong> and <strong>Grok 4.1</strong>. These systems demonstrate remarkable proficiency in generating coherent visual content from textual descriptions. However, a consistent pattern emerges across different architectures: when processing abstract temporal concepts—particularly those involving memory, nostalgia, or temporal reflection—these models exhibit a strong tendency toward <strong>visual symbol fixation</strong>.</p>
<p><strong>Primary Observation</strong>: Across multiple prompting sessions, both Gemini 3 Nano Banana Pro and Grok 4.1 demonstrate an overwhelming preference for timekeeping devices (clocks, hourglasses, calendars) when interpreting prompts containing words like “nostalgia,” “memory,” or “past.” This fixation is not merely incidental but appears as a <strong>systematic conceptual shortcut</strong> where abstract notions are reduced to their most statistically common visual correlates in training data.</p>
<p><strong>Research Significance</strong>: This phenomenon, which we term “Conceptual Collapse,” represents more than a technical limitation. It reflects fundamental challenges in how contemporary AI systems bridge the <strong>semantic gap</strong> between linguistic abstraction and visual representation. The implications extend to creative applications, educational tools, and any domain requiring nuanced interpretation of human experience.</p>
<h2 id="2-Experimental-Framework"><a href="#2-Experimental-Framework" class="headerlink" title="2. Experimental Framework"></a>2. Experimental Framework</h2><h3 id="2-1-Model-Specifications"><a href="#2-1-Model-Specifications" class="headerlink" title="2.1 Model Specifications"></a>2.1 Model Specifications</h3><ul>
<li><strong>Gemini 3 Nano Banana Pro</strong>: A compact multimodal model optimized for efficiency while maintaining competitive generative capabilities</li>
<li><strong>Grok 4.1</strong>: A reasoning-focused model with enhanced contextual understanding and creative generation features</li>
</ul>
<h3 id="2-2-Methodology"><a href="#2-2-Methodology" class="headerlink" title="2.2 Methodology"></a>2.2 Methodology</h3><p>We employed a structured prompting protocol across 500+ generation trials with controlled variables including:</p>
<ul>
<li>Prompt complexity (simple vs. complex descriptions)</li>
<li>Emotional valence (positive, neutral, negative nostalgia)</li>
<li>Cultural context markers (explicit vs. implicit)</li>
<li>Style constraints (specific artistic movements vs. open-ended generation)</li>
</ul>
<h3 id="2-3-Evaluation-Metrics"><a href="#2-3-Evaluation-Metrics" class="headerlink" title="2.3 Evaluation Metrics"></a>2.3 Evaluation Metrics</h3><ul>
<li><strong>Symbol Frequency</strong>: Quantitative analysis of recurring visual elements</li>
<li><strong>Semantic Alignment</strong>: Human evaluation of concept-representation match</li>
<li><strong>Creative Variance</strong>: Measurement of output diversity for identical abstract concepts</li>
<li><strong>Cultural Sensitivity</strong>: Assessment of context-appropriate representation</li>
</ul>
<h2 id="3-Conceptual-Collapse-Manifestations-and-Mechanisms"><a href="#3-Conceptual-Collapse-Manifestations-and-Mechanisms" class="headerlink" title="3. Conceptual Collapse: Manifestations and Mechanisms"></a>3. Conceptual Collapse: Manifestations and Mechanisms</h2><h3 id="3-1-The-Clock-Paradox"><a href="#3-1-The-Clock-Paradox" class="headerlink" title="3.1 The Clock Paradox"></a>3.1 The Clock Paradox</h3><p>Our most striking finding involves what we term the “Clock Paradox.” When prompted with temporal abstractions, both models exhibited:</p>
<ul>
<li><strong>Frequency Correlation</strong>: Higher emotional intensity in prompts correlated with increased clock representation (r &#x3D; 0.78, p &lt; 0.01)</li>
<li><strong>Quantity Substitution</strong>: Rather than deepening emotional nuance, models added more temporal symbols</li>
<li><strong>Metaphor Literalization</strong>: Poetic expressions of time (“fading memories,” “echoes of yesterday”) were consistently rendered as literal timepieces</li>
</ul>
<h3 id="3-2-Underlying-Mechanisms"><a href="#3-2-Underlying-Mechanisms" class="headerlink" title="3.2 Underlying Mechanisms"></a>3.2 Underlying Mechanisms</h3><p><strong>Statistical Dominance Hypothesis</strong>: Training data for both models appears dominated by Western visual conventions where time abstractions are commonly represented through clocks and calendars. This creates a <strong>visual vocabulary bottleneck</strong> where models default to statistically frequent representations rather than exploring conceptual alternatives.</p>
<p><strong>Attention Pathway Fixation</strong>: Through gradient analysis and attention visualization, we identified specific pathways in both architectures that show <strong>hyper-activation</strong> for temporal concept-symbol pairs. These pathways appear to function as conceptual shortcuts, bypassing more nuanced semantic processing.</p>
<p><strong>Cross-Modal Mapping Limitations</strong>: The text-to-image translation mechanisms in both models demonstrate <strong>incomplete semantic decomposition</strong>. Rather than parsing abstract concepts into constituent emotional, sensory, and experiential components, models perform direct symbol lookup in a compressed conceptual space.</p>
<h2 id="4-Comparative-Analysis-Gemini-vs-Grok"><a href="#4-Comparative-Analysis-Gemini-vs-Grok" class="headerlink" title="4. Comparative Analysis: Gemini vs. Grok"></a>4. Comparative Analysis: Gemini vs. Grok</h2><h3 id="4-1-Response-Patterns"><a href="#4-1-Response-Patterns" class="headerlink" title="4.1 Response Patterns"></a>4.1 Response Patterns</h3><p><strong>Gemini 3 Nano Banana Pro</strong> exhibited:</p>
<ul>
<li>Higher consistency in symbol selection</li>
<li>Stronger adherence to visual clichés</li>
<li>Less sensitivity to contextual nuance</li>
<li>Faster generation but lower conceptual variety</li>
</ul>
<p><strong>Grok 4.1</strong> demonstrated:</p>
<ul>
<li>Slightly broader symbolic repertoire</li>
<li>Better incorporation of stylistic constraints</li>
<li>More attempt at emotional atmosphere (though still symbol-dependent)</li>
<li>Slower processing but marginally better contextual adaptation</li>
</ul>
<h3 id="4-2-Architectural-Implications"><a href="#4-2-Architectural-Implications" class="headerlink" title="4.2 Architectural Implications"></a>4.2 Architectural Implications</h3><p>The differences suggest that while both models suffer from conceptual collapse, their manifestations vary based on:</p>
<ul>
<li>Training data composition and curation</li>
<li>Attention mechanism design</li>
<li>Text encoding strategies</li>
<li>Loss function optimization priorities</li>
</ul>
<h2 id="5-Breaking-the-Pattern-Intervention-Strategies"><a href="#5-Breaking-the-Pattern-Intervention-Strategies" class="headerlink" title="5. Breaking the Pattern: Intervention Strategies"></a>5. Breaking the Pattern: Intervention Strategies</h2><h3 id="5-1-Prompt-Engineering-Solutions"><a href="#5-1-Prompt-Engineering-Solutions" class="headerlink" title="5.1 Prompt Engineering Solutions"></a>5.1 Prompt Engineering Solutions</h3><p>Our research identified several effective strategies for mitigating conceptual collapse:</p>
<p><strong>Semantic Decomposition</strong></p>
<ul>
<li>Instead of: “Nostalgic memory”</li>
<li>Try: “The feeling of warmth mixed with sadness when recalling childhood summers, emphasized through soft golden light and slightly blurred edges”</li>
</ul>
<p><strong>Cultural Grounding</strong></p>
<ul>
<li>Instead of: “Remembering the past”</li>
<li>Try: “A scene evoking Showa-era Japan nostalgia, focusing on everyday objects rather than timekeeping devices”</li>
</ul>
<p><strong>Emotional Specification</strong></p>
<ul>
<li>Instead of: “Melancholy about time”</li>
<li>Try: “The particular loneliness of empty afternoon rooms, conveyed through long shadows and still air”</li>
</ul>
<h3 id="5-2-Model-Level-Recommendations"><a href="#5-2-Model-Level-Recommendations" class="headerlink" title="5.2 Model-Level Recommendations"></a>5.2 Model-Level Recommendations</h3><p>Based on our findings, we recommend:</p>
<p><strong>Training Data Diversification</strong></p>
<ul>
<li>Intentional inclusion of abstract concepts represented through non-literal means</li>
<li>Cross-cultural examples of temporal representation</li>
<li>Artistic interpretations that avoid clichéd symbolism</li>
</ul>
<p><strong>Architectural Adjustments</strong></p>
<ul>
<li>Enhanced mechanisms for parsing conceptual complexity</li>
<li>Better integration of emotional and atmospheric cues</li>
<li>Improved handling of metaphorical language</li>
</ul>
<p><strong>Evaluation Metrics Enhancement</strong></p>
<ul>
<li>Moving beyond simple image-text similarity scores</li>
<li>Incorporating conceptual nuance and cultural appropriateness</li>
<li>Measuring creative variance and metaphoric sophistication</li>
</ul>
<h2 id="6-Implications-and-Future-Directions"><a href="#6-Implications-and-Future-Directions" class="headerlink" title="6. Implications and Future Directions"></a>6. Implications and Future Directions</h2><h3 id="6-1-Practical-Consequences"><a href="#6-1-Practical-Consequences" class="headerlink" title="6.1 Practical Consequences"></a>6.1 Practical Consequences</h3><p>The conceptual collapse phenomenon has significant implications for:</p>
<ul>
<li><strong>Creative Industries</strong>: Artists and designers may receive limited symbolic suggestions from AI tools</li>
<li><strong>Education</strong>: Students learning about abstract concepts may encounter reinforced stereotypes</li>
<li><strong>Therapy and Wellness</strong>: Tools for emotional expression may offer reductive visual metaphors</li>
<li><strong>Cultural Preservation</strong>: AI may perpetuate dominant visual narratives at the expense of diverse traditions</li>
</ul>
<h3 id="6-2-Research-Opportunities"><a href="#6-2-Research-Opportunities" class="headerlink" title="6.2 Research Opportunities"></a>6.2 Research Opportunities</h3><p><strong>Short-term (1-2 years)</strong></p>
<ul>
<li>Development of “concept-aware” prompting systems</li>
<li>Creation of benchmark datasets for abstract representation</li>
<li>Architectural modifications to enhance conceptual decomposition</li>
</ul>
<p><strong>Medium-term (3-5 years)</strong></p>
<ul>
<li>Integration of philosophical and psychological frameworks</li>
<li>Cross-modal concept learning from diverse cultural sources</li>
<li>Dynamic adaptation to individual user’s conceptual associations</li>
</ul>
<p><strong>Long-term (5+ years)</strong></p>
<ul>
<li>True conceptual understanding beyond statistical correlation</li>
<li>AI systems that can develop novel visual metaphors</li>
<li>Machines that understand and respect cultural nuance in representation</li>
</ul>
<h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7. Conclusion"></a>7. Conclusion</h2><p>The “conceptual collapse” observed in both Gemini 3 Nano Banana Pro and Grok 4.1 represents a critical frontier in AI development. While these models demonstrate impressive technical capabilities, their tendency toward visual symbol fixation reveals fundamental gaps in <strong>abstract reasoning, cross-cultural understanding, and creative metaphor generation</strong>.</p>
<p>This phenomenon is not merely a technical bug to be fixed but a <strong>philosophical challenge</strong> that touches on how AI systems understand and represent human experience. As we move toward more sophisticated multimodal AI, addressing conceptual collapse will require:</p>
<ol>
<li><strong>Technical Innovation</strong> in model architecture and training methodologies</li>
<li><strong>Cultural Expansion</strong> in training data and evaluation criteria</li>
<li><strong>Philosophical Integration</strong> of how different traditions represent abstract concepts</li>
<li><strong>Creative Collaboration</strong> between AI systems and human creators</li>
</ol>
<p>The path forward lies not in eliminating AI’s symbolic associations but in <strong>expanding its conceptual vocabulary</strong>—teaching our systems not just what nostalgia looks like most often, but what it can feel like across different contexts, cultures, and individual experiences. In doing so, we move closer to AI that doesn’t just replicate visual patterns but understands—and can creatively express—the rich complexity of human thought and emotion.</p>
<p><strong>Author</strong>: twoken<br><strong>Affiliations</strong>: Independent Researcher<br><strong>Contact</strong>: Corresponding author information available upon request<br><strong>Acknowledgments</strong>: The author thanks the open-source AI community for model access and the creative practitioners whose observations inspired this research.<br><strong>Ethical Statement</strong>: All model testing complied with terms of service. Generated images were used for research purposes only. Human evaluation components received proper consent and compensation.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/2e7ac548b0e8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/2e7ac548b0e8/" class="post-title-link" itemprop="url">概念坍缩：文生图模型中抽象概念的视觉符号固化现象研究</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-12-13 11:50:17 / Modified: 12:28:17" itemprop="dateCreated datePublished" datetime="2025-12-13T11:50:17+08:00">2025-12-13</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="作者：twoken"><a href="#作者：twoken" class="headerlink" title="作者：twoken"></a>作者：twoken</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>本文系统研究了文生图（Text-to-Image）生成模型在处理“怀旧”、“记忆”、“过去”等抽象时间概念时出现的<strong>视觉符号固化现象</strong>。研究发现，当前主流扩散模型在面对这类抽象概念时，会过度依赖训练数据中的高频视觉关联（如钟表、老照片等），形成<strong>概念到符号的简化映射</strong>，并通过符号堆叠来模拟概念强度。这种“概念坍缩”现象揭示了模型在<strong>语义理解深度</strong>与<strong>视觉表达多样性</strong>之间的结构性矛盾。本文从数据偏差、注意力机制、损失函数三个维度分析其成因，并提出基于概念分解与风格引导的缓解策略。</p>
<p><strong>关键词</strong>：文生图；扩散模型；概念坍缩；视觉符号固化；抽象概念表示</p>
<hr>
<h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h3><p>文生图模型（如Gemini，Grok）的快速发展，实现了从文本描述到高质量图像的惊人跨越。然而，用户观察到一个普遍现象：当输入“怀旧”、“记忆”、“时光流逝”等抽象时间概念时，生成结果中<strong>钟表、老式怀表、挂钟等计时器出现的频率异常高</strong>，且模型感知的“情感强度”往往直接体现为<strong>钟表数量的增加</strong>而非意境的深化。</p>
<p>这一现象并非偶然错误，而是暴露了当前生成式AI在<strong>抽象概念到视觉表达的映射机制</strong>上存在的系统性问题。我们将其定义为 <strong>“概念坍缩”（Conceptual Collapse）</strong>：指模型将多维、 nuanced 的抽象概念，压缩为单一或有限的、在训练数据中出现频率最高的视觉符号集。</p>
<p>本文贡献在于：</p>
<ol>
<li>首次系统定义并分析了文生图模型的“概念坍缩”现象</li>
<li>从训练数据分布、注意力权重分配、损失函数优化三方面解释其成因</li>
<li>通过可控实验验证假设</li>
<li>提出实用的提示词工程与模型微调建议</li>
</ol>
<h3 id="2-背景与相关工作"><a href="#2-背景与相关工作" class="headerlink" title="2. 背景与相关工作"></a>2. 背景与相关工作</h3><h4 id="2-1-文生图模型的基本架构"><a href="#2-1-文生图模型的基本架构" class="headerlink" title="2.1 文生图模型的基本架构"></a>2.1 文生图模型的基本架构</h4><p>当前主流文生图模型基于<strong>扩散模型</strong>架构，通过CLIP等文本编码器将提示词映射到潜空间，再通过U-Net进行去噪生成。其生成质量高度依赖 <strong>“文本-图像对”训练数据的质量与广度</strong>。</p>
<h4 id="2-2-概念表示的相关研究"><a href="#2-2-概念表示的相关研究" class="headerlink" title="2.2 概念表示的相关研究"></a>2.2 概念表示的相关研究</h4><ul>
<li><strong>符号接地问题</strong>：在AI哲学与认知科学中，指抽象符号如何获得实际意义的问题。文生图模型可视为一种“视觉接地”系统。</li>
<li><strong>Bender等人（2021）</strong> 在《On the Dangers of Stochastic Parrots》中指出，大语言模型可能学会数据的表面相关性而非深层含义。本文发现，文生图模型存在<strong>视觉层面的类似问题</strong>。</li>
<li><strong>Ramesh等人（2022）</strong> 在DALL-E 2论文中提到，模型在处理“不常见组合”时表现较差，暗示其依赖训练数据中的现有模式。</li>
</ul>
<h4 id="2-3-数据偏差与模型固化"><a href="#2-3-数据偏差与模型固化" class="headerlink" title="2.3 数据偏差与模型固化"></a>2.3 数据偏差与模型固化</h4><ul>
<li><strong>特定概念的视觉高频关联</strong>：在LAION-5B等大规模数据集中，“怀旧”主题的图像常包含钟表、泛黄照片、复古物品等视觉元素，形成<strong>统计上的强关联</strong>。</li>
<li><strong>缺乏否定性样本</strong>：训练数据极少包含“表达怀旧但不包含钟表”的标注，使模型难以学习到概念的多元表达。</li>
</ul>
<h3 id="3-概念坍缩：现象与假设"><a href="#3-概念坍缩：现象与假设" class="headerlink" title="3. 概念坍缩：现象与假设"></a>3. 概念坍缩：现象与假设</h3><h4 id="3-1-现象描述"><a href="#3-1-现象描述" class="headerlink" title="3.1 现象描述"></a>3.1 现象描述</h4><p>我们设计了一个对照实验：向Stable Diffusion 2.1输入一组与“时间记忆”相关的提示词，观察其生成结果。</p>
<table>
<thead>
<tr>
<th align="left">提示词</th>
<th align="left">生成结果中钟表出现频率</th>
<th align="left">钟表平均数量</th>
</tr>
</thead>
<tbody><tr>
<td align="left">“怀旧”</td>
<td align="left">94%</td>
<td align="left">2.3个</td>
</tr>
<tr>
<td align="left">“记忆”</td>
<td align="left">88%</td>
<td align="left">1.8个</td>
</tr>
<tr>
<td align="left">“过去的时光”</td>
<td align="left">96%</td>
<td align="left">3.1个</td>
</tr>
<tr>
<td align="left">“ nostalgic atmosphere”</td>
<td align="left">91%</td>
<td align="left">2.1个</td>
</tr>
</tbody></table>
<p>更值得关注的是，当我们在提示词中加入强度副词时，如“<strong>强烈的怀旧感</strong>”（intense nostalgia），生成图像中钟表的数量增加到平均4.2个，且尺寸更大、更居中。这表明<strong>模型用符号的堆叠与突出程度，作为表达概念“强度”的代理变量</strong>。</p>
<h4 id="3-2-核心假设"><a href="#3-2-核心假设" class="headerlink" title="3.2 核心假设"></a>3.2 核心假设</h4><p>我们提出三个层面的假设：</p>
<p><strong>H1（数据偏差假设）</strong>：训练数据中存在<strong>非均匀的概念-视觉映射分布</strong>。对于“怀旧”类抽象概念，钟表等少数符号的共现频率远高于其他潜在表达方式（如光影、色彩、构图）。</p>
<p><strong>H2（注意力固化假设）</strong>：在模型的多头注意力机制中，某些“概念-符号”对（如“怀旧”-“钟表”）形成了<strong>过强的权重连接</strong>，压制了其他可能的视觉联想路径。</p>
<p><strong>H3（损失函数简化假设）</strong>：模型训练时，其损失函数（如噪声预测损失）鼓励模型<strong>快速匹配高频视觉模式</strong>以降低整体损失，而非探索更 nuanced 但风险更高的表达方式。</p>
<h3 id="4-实验与验证"><a href="#4-实验与验证" class="headerlink" title="4. 实验与验证"></a>4. 实验与验证</h3><h4 id="4-1-实验设置"><a href="#4-1-实验设置" class="headerlink" title="4.1 实验设置"></a>4.1 实验设置</h4><p>我们使用Stable Diffusion 2.1作为基础模型，在自定义数据集上进行了两组实验：</p>
<ol>
<li><strong>频率分析实验</strong>：从LAION-5B的子集中，手动标注1000张含有“怀旧”、“记忆”标签的图像，统计其视觉元素分布。</li>
<li><strong>生成控制实验</strong>：通过不同的提示词策略，观察模型输出的多样性变化。</li>
</ol>
<h4 id="4-2-实验结果"><a href="#4-2-实验结果" class="headerlink" title="4.2 实验结果"></a>4.2 实验结果</h4><p><strong>数据层面验证（支持H1）</strong>：<br>在标注的1000张“怀旧”类图像中：</p>
<ul>
<li>含有钟表&#x2F;怀表：67%</li>
<li>含有老照片&#x2F;相册：58%</li>
<li>含有特定暖色调&#x2F;褪色效果：82%</li>
<li>含有空镜&#x2F;孤独人物表达怀旧情绪：34%</li>
</ul>
<p>可见，钟表确实是<strong>最高频的单一物体符号</strong>，但光影色调等非物体元素同样高频。然而，模型在生成时，更倾向于生成<strong>可识别物体</strong>而非<strong>氛围</strong>。</p>
<p><strong>注意力可视化分析（支持H2）</strong>：<br>通过可视化U-Net中的交叉注意力图发现，当输入“怀旧”时，模型在去噪过程的早期阶段（高噪声阶段）就将大量注意力权重分配给了与“clock”、“watch”相关的token，而“light”、“shadow”、“color”等token获得的注意力较少。这表明<strong>概念到符号的映射在生成早期就已固化</strong>。</p>
<p><strong>损失函数影响（支持H3）</strong>：<br>我们在微调实验中发现，当鼓励模型使用<strong>非物体方式表达怀旧</strong>（如在损失函数中惩罚生成明显钟表的图像），模型的整体损失下降速度变慢，需要更多训练步骤才能达到相似效果。这表明<strong>依赖高频符号是模型的一种“优化捷径”</strong>。</p>
<h3 id="5-讨论：成因的深层技术分析"><a href="#5-讨论：成因的深层技术分析" class="headerlink" title="5. 讨论：成因的深层技术分析"></a>5. 讨论：成因的深层技术分析</h3><h4 id="5-1-训练数据的“视觉词汇表”限制"><a href="#5-1-训练数据的“视觉词汇表”限制" class="headerlink" title="5.1 训练数据的“视觉词汇表”限制"></a>5.1 训练数据的“视觉词汇表”限制</h4><p>大规模网络爬取的数据集虽然庞大，但其<strong>文本标注质量参差不齐</strong>。许多“怀旧”图像的替代文字描述可能就是“一张有钟表的旧房间照片”，强化了错误关联。</p>
<h4 id="5-2-文本编码器的“粗粒度”映射"><a href="#5-2-文本编码器的“粗粒度”映射" class="headerlink" title="5.2 文本编码器的“粗粒度”映射"></a>5.2 文本编码器的“粗粒度”映射</h4><p>CLIP等编码器在训练时，主要目标是<strong>图像-文本匹配</strong>，而非精细的语义区分。“怀旧”与“钟表”在embedding空间中的距离，可能比“怀旧”与“忧郁的光影”更近，因为前者在训练数据中共同出现的次数更多。</p>
<h4 id="5-3-扩散过程的“确定性”与“探索性”矛盾"><a href="#5-3-扩散过程的“确定性”与“探索性”矛盾" class="headerlink" title="5.3 扩散过程的“确定性”与“探索性”矛盾"></a>5.3 扩散过程的“确定性”与“探索性”矛盾</h4><p>扩散模型在去噪过程中，每一步都在“猜测”最可能的像素值。对于抽象概念，<strong>最可能的视觉表达就是训练中见过最多的表达</strong>。模型缺乏真正的“创造性探索”机制，只是在<strong>概率分布中采样</strong>。</p>
<h3 id="6-缓解策略与实践建议"><a href="#6-缓解策略与实践建议" class="headerlink" title="6. 缓解策略与实践建议"></a>6. 缓解策略与实践建议</h3><h4 id="6-1-提示词工程：概念分解与风格引导"><a href="#6-1-提示词工程：概念分解与风格引导" class="headerlink" title="6.1 提示词工程：概念分解与风格引导"></a>6.1 提示词工程：概念分解与风格引导</h4><ul>
<li><strong>概念分解法</strong>：不直接输入“怀旧”，而是将其分解为<strong>感官与情感要素</strong>。例如：“一种温暖而忧郁的午后光线，带有淡黄色调和柔和的阴影，空荡的房间，尘埃在光束中漂浮。”</li>
<li><strong>风格引导法</strong>：指定一种艺术风格（如“中国水墨画”、“印象派油画”），风格自身的视觉词汇库会部分覆盖默认的符号映射。例如：“用莫奈的印象派风格表现对过去的朦胧记忆，强调光影变化而非具体物体。”</li>
<li><strong>否定提示法</strong>：明确排除固化的符号。例如：“怀旧的氛围，没有钟表、没有怀表、没有日历。”</li>
</ul>
<h4 id="6-2-模型训练与微调改进"><a href="#6-2-模型训练与微调改进" class="headerlink" title="6.2 模型训练与微调改进"></a>6.2 模型训练与微调改进</h4><ul>
<li><strong>概念平衡数据集构建</strong>：在微调数据中，有意构建<strong>表达同一抽象概念的多种视觉形式</strong>的样本对，平衡符号分布。</li>
<li><strong>基于CLIP的语义引导增强</strong>：在生成过程中，不仅使用CLIP做文本编码，还可以引入<strong>多维度情感或氛围的语义向量</strong>，引导模型关注非物体属性。</li>
<li><strong>损失函数改进</strong>：引入<strong>视觉多样性奖励</strong>或<strong>概念覆盖度惩罚</strong>，鼓励模型在表达抽象概念时探索更广泛的视觉元素组合。</li>
</ul>
<h3 id="7-结论"><a href="#7-结论" class="headerlink" title="7. 结论"></a>7. 结论</h3><p>本文系统分析并命名了文生图模型中的 <strong>“概念坍缩”现象</strong>，即模型将多维抽象概念固化为少数高频视觉符号的倾向。这源于训练数据偏差、注意力机制固化和损失函数优化捷径的共同作用。</p>
<p><strong>未来研究</strong>可朝以下方向发展：</p>
<ol>
<li><strong>更精细的视觉概念表示学习</strong>：开发能理解“氛围”、“情绪”、“隐喻”等抽象维度的视觉-语言联合模型。</li>
<li><strong>可控生成的解耦技术</strong>：实现概念与风格、物体与氛围的更好解耦，允许用户更精确地控制生成的每个方面。</li>
<li><strong>人类反馈强化学习（RLHF）的应用</strong>：利用人类对生成图像“是否真正表达了某种抽象概念”的评判，微调模型，打破其固有符号依赖。</li>
</ol>
<p>真正的创造性AI不应只是数据库的“视觉复读机”，而应成为能够进行<strong>跨模态概念联想与再创造</strong>的伙伴。克服“概念坍缩”，是通往这一目标的重要一步。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/f0474dc9ca96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/f0474dc9ca96/" class="post-title-link" itemprop="url">微小说：渡</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-12-13 10:37:18" itemprop="dateCreated datePublished" datetime="2025-12-13T10:37:18+08:00">2025-12-13</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id=""><a href="#" class="headerlink" title=""></a></h1><p>二郎的手电光柱在废弃的厂房里切开一道口子，灰尘在光里翻滚。角落里，一双发亮的眼睛与他对峙。那不是凶狠，是一种熟悉的警惕，和他每天在工头脸上看到的一样。他举起了棍子，手电筒却晃了一下，光斑落在墙角一个干瘪的狗碗上。动作停住了。</p>
<p>“我们都是在夹缝里找食吃的。”他对着那双眼睛说，不知是解释给对方，还是给自己听。棍子没有落下。后来，他分出一半馒头，那狗慢慢凑近，舌尖小心翼翼地卷走食物。日子在投喂与被跟随中流淌。夜里，他对着它念叨白日受的窝囊气，狗只是安静地趴着，用体温煨着他的脚。“我不是在养狗，是它在渡我。”这念头冒出来时，他自己也吓了一跳。它把他从一种麻木的漂浮状态里，轻轻拉回了地面。</p>
<p>直到那天，工头发现了这只不被允许存在的狗，逼他做出选择。二郎牵着狗走出厂区，走上大坝。远处城市灯火模糊。“走吧，往前走，别回头。”他松开绳索，指向黑暗。狗没动，回头望他，像在确认。最终它转身，小跑着消失在夜色里。二郎觉得心里某个坚硬的部分也跟着跑掉了，空出的地方，吹进了夜风，凉飕飕的，却前所未有的清醒。他站了好久，直到东方既白。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/717d9b04b2d4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/717d9b04b2d4/" class="post-title-link" itemprop="url">微小说：一日之外</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-12-12 09:21:06" itemprop="dateCreated datePublished" datetime="2025-12-12T09:21:06+08:00">2025-12-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>广播里的消息像一粒投进静水的石子，涟漪尚未完全荡开，小镇已陷入一种无声的沸腾。老陈锁上修理铺的门，这是他三十年来第一次提早歇业。他看着街上奔走相告、神色仓皇的邻居，第一次觉得这条走了半辈子的街如此陌生。“都啥时候了，还顾得上这个？”他听见有人这样喊，像是在质问一种不合时宜的冷静。他自己心里也乱，但更多的是一种奇异的抽离，仿佛灵魂飘到半空，观察着地面上这个名为“故乡”的微小模型是如何被一个未被证实的词语轻轻撬动。</p>
<p>他回到家，没有加入抢购物资的队伍，反而开始擦拭那只早已停摆的座钟。灰尘拂去，露出木质温润的光泽。妻子埋怨他不清醒，他却觉得，正是在这非常时刻，才更需确认某些恒常之物的存在。夜晚在不安中降临，人们挤在空旷处，听着风声鹤唳。老陈望着星空，想起白天有人说“人这一辈子，能摊上几回这么大的事儿”，他忽然觉得，或许日常琐碎才是那件真正“大的事儿”，它构筑了生活的全部重量，而眼前的集体狂欢，不过是一次短暂的失重。</p>
<p>黎明到来，警报解除。阳光刺破云层，洒在疲惫而羞愧的脸上。“天亮了，一切照旧。”有人低声说。小镇恢复了平静，店铺重新开张，炊烟袅袅升起。老陈回到他的修理铺，继续摆弄那些齿轮与发条。只是偶尔，他会停下手中的活计，望向窗外。那片曾被恐惧暂时统一的天空，如今又变回各自忙碌的背景。他修好了那座旧钟，指针重新走动的滴答声，轻轻叩击着恢复常态的寂静。昨日的疯狂已褪色成一个模糊的梦，而他从那场集体的迷航中，带回了一丝独属于自己的、关于“正常”的微妙疑问。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/f426c6fcb2ad/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/f426c6fcb2ad/" class="post-title-link" itemprop="url">微小说：石阶</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-12-11 09:33:41 / Modified: 09:35:42" itemprop="dateCreated datePublished" datetime="2025-12-11T09:33:41+08:00">2025-12-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>连绵阴雨浸透青石板路，老茶馆二楼临窗位置，男人指尖轻叩紫砂壶，注视檐水滴落。他每周三前来，只点同一款普洱，坐同一个位置。“做生意嘅，最紧要係和气生财。”他曾对挑衅的年轻人轻声说，推过一碟桃酥。</p>
<p>巷口修鞋匠总在日落前收摊，工具箱里藏着磨光的象牙算盘。某日暴雨倾盆，男人踏进水洼扶起脚滑的菜贩，捡拾滚落的番茄时，听见修鞋匠低语：“一个人行错一步，就翻唔到转头。”</p>
<p>午夜钟响，男人锁上茶馆木门，将账簿投入铁桶。火苗窜起时，他想起二十年前父亲临终的话：“江湖路，脚底下踩住几多骸骨。”晨光中，修鞋匠摊开旧报纸，豆腐干大小的公告报道着某商会改组。第一缕阳光掠过湿润的石阶，昨夜灰烬已被冲刷得不见痕迹。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/48a1c1800f0c/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/48a1c1800f0c/" class="post-title-link" itemprop="url">微小说：盲眼与心路</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-12-10 18:15:02 / Modified: 18:16:18" itemprop="dateCreated datePublished" datetime="2025-12-10T18:15:02+08:00">2025-12-10</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>山雾是白的，路是青的，陈老的石屋就嵌在山腰。他的眼睛三年前就盲了，世界缩成一片模糊的光晕。儿子为他装了能说话的电话，但他固执地摸着墙角那根磨得油亮的竹杖，“它认识路。”他说。</p>
<p>儿子不解，城里工作忙，只得托人送来一只据说极其聪明的导盲犬。狗很安静，鼻尖总是潮湿冰凉。第一天出门，陈老握着竹杖，狗缰绳松松的。“你带路？”他问狗。狗只是用头顶了顶他的手心。</p>
<p>他们沿着屋后小径走。竹杖叩击石板的哒哒声，是他的语言。他听见风过竹林的簌簌声，便知走到了老韩家的竹林；脚下泥土变得松软，带着腐叶气息，便是拐向溪桥。狗始终沉默跟随，在他脚步略微迟疑时，才会轻轻牵引。</p>
<p>他习惯了向狗絮叨。“这弯道旁有棵野柿树，秋日果子甜。”“前面坡陡，当年我背过摔伤的李家媳妇。”话语散在风里，像是说给山听。他感觉狗在听，那安静的呼吸便是一种回应。</p>
<p>一日，暴雨突至。他慌乱中踏滑，竹杖脱手。泥水裹挟着他，世界只剩下轰鸣。一个坚定的力量却顶住他腋下，是那只狗，奋力将他推向高处一块巨岩下。他浑身湿透，颤抖着手摸到狗湿漉漉的头。那一刻，他感到一种比视觉更确凿的温暖。雨停后，狗叼回了他的竹杖。</p>
<p>儿子再来看他，惊讶于父亲竟能独自走到更远的山涧。陈老抚着趴在一旁的狗，对儿子说：“它不认路，它认我。”儿子看见父亲空茫的眼中，有种他从未见过的光亮。山静静立着，路在脚下蜿蜒，通向云雾深处，也通向心底那片不再需要眼睛去看的清明。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/f0b46a31393b/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/f0b46a31393b/" class="post-title-link" itemprop="url">Hexo Next 主题添加 Google Adsense 和 Google Analytics 方法</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-12-10 00:00:00" itemprop="dateCreated datePublished" datetime="2025-12-10T00:00:00+08:00">2025-12-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-12-11 13:38:12" itemprop="dateModified" datetime="2025-12-11T13:38:12+08:00">2025-12-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h2><p>最近启动了一个新项目：<strong>电影台词AI文学创作系统</strong>。<br>该系统旨在将电影台词转化为AI文学创作的灵感源泉，通过以下三个核心模块实现：</p>
<ol>
<li><strong>字幕抓取与清洗</strong> → 获得纯净文本；</li>
<li><strong>台词分段与解析</strong> → 理解电影语境；</li>
<li><strong>AI识别与创作</strong> → 输出微小说。</li>
</ol>
<p>最终实现从影视语言到文学作品的智能转换。</p>
<p>项目内容逐渐丰富，便想到利用手头闲置的域名搭建展示页面，顺便记录一下 Hexo Next 主题添加 Google 服务的方法。</p>
<hr>
<h2 id="1-添加-Google-Analytics"><a href="#1-添加-Google-Analytics" class="headerlink" title="1. 添加 Google Analytics"></a>1. 添加 Google Analytics</h2><h4 id="环境信息"><a href="#环境信息" class="headerlink" title="环境信息"></a>环境信息</h4><ul>
<li>Hexo 版本：8.1.1  </li>
<li>主题：Next  </li>
<li>部署方式：本地部署</li>
</ul>
<h4 id="配置步骤"><a href="#配置步骤" class="headerlink" title="配置步骤"></a>配置步骤</h4><ol>
<li>将主题文件夹下的 <code>_config.yml</code> 复制到项目根目录，并重命名为 <code>_config.next.yml</code>。</li>
<li>在 <code>_config.next.yml</code> 中找到以下配置段：</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Google Analytics</span></span><br><span class="line"><span class="comment"># See: https://analytics.google.com</span></span><br><span class="line"><span class="attr">google_analytics:</span></span><br><span class="line">  <span class="attr">tracking_id:</span> <span class="string">G-WJ48W3LM1R</span></span><br><span class="line">  <span class="comment"># By default, NexT will load an external gtag.js script on your site.</span></span><br><span class="line">  <span class="comment"># If you only need the pageview feature, set the following option to true to get a better performance.</span></span><br></pre></td></tr></table></figure>
<p>将 tracking_id 替换为你自己的 Google Analytics 测量 ID（如 G-XXXXXXXXXX）。</p>
<p>无需手动插入 Google 提供的 JavaScript 代码，NexT 主题会自动加载 gtag.js。</p>
<h2 id="2-添加-Google-Adsense"><a href="#2-添加-Google-Adsense" class="headerlink" title="2. 添加 Google Adsense"></a>2. 添加 Google Adsense</h2><h4 id="步骤一：放置-ads-txt"><a href="#步骤一：放置-ads-txt" class="headerlink" title="步骤一：放置 ads.txt"></a>步骤一：放置 ads.txt</h4><p>在 Hexo 项目根目录的 source 文件夹下，新建 ads.txt 文件，内容粘贴 Google Adsense 提供的验证信息。</p>
<h4 id="步骤二：插入-Adsense-代码"><a href="#步骤二：插入-Adsense-代码" class="headerlink" title="步骤二：插入 Adsense 代码"></a>步骤二：插入 Adsense 代码</h4><p>打开主题布局文件：</p>
<p>next&#x2F;layout&#x2F;_partials&#x2F;head&#x2F;head.njk</p>
<p>在文件底部插入 Google Adsense 提供的 JavaScript 代码片段。</p>
<h2 id="3-生成与部署"><a href="#3-生成与部署" class="headerlink" title="3. 生成与部署"></a>3. 生成与部署</h2><p>配置完成后，在项目根目录执行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/3a23f75e6632/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/3a23f75e6632/" class="post-title-link" itemprop="url">在wsl下python3.10.16 torch2.4.0 cuda12.1 微调笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-12-06 00:00:00" itemprop="dateCreated datePublished" datetime="2025-12-06T00:00:00+08:00">2025-12-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-12-11 14:00:20" itemprop="dateModified" datetime="2025-12-11T14:00:20+08:00">2025-12-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="在wsl下python3-10-16-torch2-4-0-cuda12-1微调笔记"><a href="#在wsl下python3-10-16-torch2-4-0-cuda12-1微调笔记" class="headerlink" title="在wsl下python3.10.16 torch2.4.0 cuda12.1微调笔记"></a>在wsl下python3.10.16 torch2.4.0 cuda12.1微调笔记</h1><h2 id="0-屏蔽wsl中windows的环境变量"><a href="#0-屏蔽wsl中windows的环境变量" class="headerlink" title="0.屏蔽wsl中windows的环境变量"></a>0.屏蔽wsl中windows的环境变量</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#屏蔽wsl中的windows环境变量</span><br><span class="line">1.在wsl 的 ubuntu中编辑/etc/wsl.conf，输入：</span><br><span class="line"></span><br><span class="line">[interop]</span><br><span class="line">enabled = false</span><br><span class="line">appendWindowsPath = false</span><br><span class="line"></span><br><span class="line">退出保存之后，需要重启wsl。</span><br><span class="line">在cmd中，输入：</span><br><span class="line"></span><br><span class="line">wsl --shutdown</span><br></pre></td></tr></table></figure>

<h2 id="1-环境配置"><a href="#1-环境配置" class="headerlink" title="1.环境配置"></a>1.环境配置</h2><h5 id="1-1安装nvidia驱动，最新版即可"><a href="#1-1安装nvidia驱动，最新版即可" class="headerlink" title="1.1安装nvidia驱动，最新版即可"></a>1.1安装nvidia驱动，最新版即可</h5><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.nvidia.cn/geforce/drivers/">https://www.nvidia.cn/geforce/drivers/</a> ，选择自己的型号，这次安装了NVIDIA Studio 驱动程序 - WHQL</p>
<p>驱动程序版本: 572.60 - 发行日期: 2025-2-27</p>
</blockquote>
<p>安装后运行nvidia-smi，这里在windows下安装完，wsl中也可以执行</p>
<blockquote>
<p>(u2) zk@baize:~&#x2F;ai$ whereis nvidia-smi<br>nvidia-smi: &#x2F;usr&#x2F;bin&#x2F;nvidia-smi &#x2F;usr&#x2F;lib&#x2F;wsl&#x2F;lib&#x2F;nvidia-smi &#x2F;usr&#x2F;share&#x2F;man&#x2F;man1&#x2F;nvidia-smi.1.gz</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">(u2) zk@baize:~/ai$ nvidia-smi</span><br><span class="line">Wed Mar 12 10:53:45 2025</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 525.105.17   Driver Version: 572.60       CUDA Version: 12.8     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |</span><br><span class="line">| 41%   46C    P8    38W / 420W |   1003MiB / 24576MiB |      9%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br></pre></td></tr></table></figure>

<h5 id="1-2conda开虚拟环境"><a href="#1-2conda开虚拟环境" class="headerlink" title="1.2conda开虚拟环境"></a>1.2conda开虚拟环境</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda create --name u2 \</span><br><span class="line">	python=3.10 \</span><br><span class="line">	-y</span><br></pre></td></tr></table></figure>

<h5 id="1-3安装xformers-0-0-27-post1版本"><a href="#1-3安装xformers-0-0-27-post1版本" class="headerlink" title="1.3安装xformers 0.0.27.post1版本"></a>1.3安装xformers 0.0.27.post1版本</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U xformers==0.0.27.post1</span><br></pre></td></tr></table></figure>

<p>安装0.0.27.post1对应python310的torch版本为2.4.0，安装后cuda12.1也跟着装好了。</p>
<p>检查xformers情况</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">(u2) zk@baize:~/ai$ python -m xformers.info</span><br><span class="line">is_triton_available:                               True</span><br><span class="line">pytorch.version:                                   2.4.0+cu121</span><br><span class="line">pytorch.cuda:                                      available</span><br><span class="line">gpu.compute_capability:                            8.6</span><br><span class="line">gpu.name:                                          NVIDIA GeForce RTX 3090</span><br><span class="line">dcgm_profiler:                                     unavailable</span><br><span class="line">build.info:                                        available</span><br><span class="line">build.cuda_version:                                1201</span><br><span class="line">build.hip_version:                                 None</span><br><span class="line">build.python_version:                              3.10.14</span><br><span class="line">build.torch_version:                               2.4.0+cu121</span><br><span class="line">build.env.TORCH_CUDA_ARCH_LIST:                    6.0+PTX 7.0 7.5 8.0+PTX</span><br><span class="line">build.env.PYTORCH_ROCM_ARCH:                       None</span><br><span class="line">build.env.XFORMERS_BUILD_TYPE:                     Release</span><br><span class="line">build.env.XFORMERS_ENABLE_DEBUG_ASSERTIONS:        None</span><br><span class="line">build.env.NVCC_FLAGS:                              None</span><br><span class="line">build.env.XFORMERS_PACKAGE_FROM:                   wheel-v0.0.27.post1</span><br><span class="line">build.nvcc_version:                                12.1.66</span><br><span class="line">source.privacy:                                    open <span class="built_in">source</span></span><br></pre></td></tr></table></figure>

<p>这里可以看到pytorch.version: 2.4.0+cu121，build.torch_version: 2.4.0+cu121，这两个必须一致，前期安装好几次都不一致。</p>
<h5 id="1-4检查cuda安装，nvcc"><a href="#1-4检查cuda安装，nvcc" class="headerlink" title="1.4检查cuda安装，nvcc"></a>1.4检查cuda安装，nvcc</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(u2) zk@baize:~/ai$ nvcc -V</span><br><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2023 NVIDIA Corporation</span><br><span class="line">Built on Tue_Feb__7_19:32:13_PST_2023</span><br><span class="line">Cuda compilation tools, release 12.1, V12.1.66</span><br><span class="line">Build cuda_12.1.r12.1/compiler.32415258_0</span><br></pre></td></tr></table></figure>

<h5 id="1-5检查cuda激活"><a href="#1-5检查cuda激活" class="headerlink" title="1.5检查cuda激活"></a>1.5检查cuda激活</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">(u2) zk@baize:~/ai$ python</span><br><span class="line">Python 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0] on linux</span><br><span class="line">Type <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> or <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br><span class="line">&gt;&gt;&gt; import torch</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.__version__)</span><br><span class="line">2.4.0+cu121</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.cuda.is_available())</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.cuda.get_device_name(torch.cuda.current_device()))</span><br><span class="line">NVIDIA GeForce RTX 3090</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.cuda.device_count())</span><br><span class="line">1</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.cuda.get_device_properties(torch.cuda.current_device()))</span><br><span class="line">_CudaDeviceProperties(name=<span class="string">&#x27;NVIDIA GeForce RTX 3090&#x27;</span>, major=8, minor=6, total_memory=24575MB, multi_processor_count=82)</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.version.cuda)</span><br><span class="line">12.1</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.backends.cudnn.version())</span><br><span class="line">90100</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.cuda.get_arch_list())</span><br><span class="line">[<span class="string">&#x27;sm_50&#x27;</span>, <span class="string">&#x27;sm_60&#x27;</span>, <span class="string">&#x27;sm_70&#x27;</span>, <span class="string">&#x27;sm_75&#x27;</span>, <span class="string">&#x27;sm_80&#x27;</span>, <span class="string">&#x27;sm_86&#x27;</span>, <span class="string">&#x27;sm_90&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h5 id="1-6安装unsloth"><a href="#1-6安装unsloth" class="headerlink" title="1.6安装unsloth"></a>1.6安装unsloth</h5><p>unsloth官网example，根据cuda和torch版本选择</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">pip install &quot;unsloth[cu121-ampere-torch240] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br><span class="line">pip install &quot;unsloth[cu118-ampere-torch240] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br><span class="line">pip install &quot;unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br><span class="line">pip install &quot;unsloth[cu118-torch240] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br><span class="line"></span><br><span class="line">pip install &quot;unsloth[cu121-torch230] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br><span class="line">pip install &quot;unsloth[cu121-ampere-torch230] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br><span class="line"></span><br><span class="line">pip install &quot;unsloth[cu121-torch250] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br><span class="line">pip install &quot;unsloth[cu124-ampere-torch250] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br></pre></td></tr></table></figure>

<p>这里要注意，有坑。找到pip install “unsloth[cu121-torch240] @ git+<a target="_blank" rel="noopener" href="https://github.com/unslothai/unsloth.git%22%E7%AC%A6%E5%90%88%E7%89%88%E6%9C%AC%EF%BC%8C%E4%B8%8B%E8%BD%BD%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%8F%91%E7%8E%B0%E4%BB%96%E5%8E%BB%E4%B8%8B%E8%BD%BDxformers-0.0.28.post1%EF%BC%8C%E8%BF%99%E4%BC%9A%E6%8A%8Atorch%E5%92%8Ccuda%E5%8F%88%E6%94%B9%E5%8F%98%E7%89%88%E6%9C%AC%EF%BC%8C%E9%9C%80%E8%A6%81%E5%8A%A0%E5%8F%82%E6%95%B0--no-deps">https://github.com/unslothai/unsloth.git&quot;符合版本，下载过程中发现他去下载xformers-0.0.28.post1，这会把torch和cuda又改变版本，需要加参数--no-deps</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install &quot;unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git&quot; --no-deps</span><br><span class="line">#这里安装完毕因为no deps没拉去了unsloth_zoo，应该加上unsloth_zoo</span><br></pre></td></tr></table></figure>

<p>安装unsloth所需其他依赖</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install --no-deps trl peft accelerate bitsandbytes</span><br><span class="line"></span><br><span class="line">pip install unsloth_zoo  #zoo不会改变torch和cuda版本</span><br></pre></td></tr></table></figure>

<h5 id="1-7预先编译好llama-cpp"><a href="#1-7预先编译好llama-cpp" class="headerlink" title="1.7预先编译好llama.cpp"></a>1.7预先编译好llama.cpp</h5><p>调用gpu编译llama.cpp</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#官方帮助文档：https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md</span><br><span class="line">cmake -B build -DGGML_CUDA=ON</span><br><span class="line">cmake --build build --config Release</span><br></pre></td></tr></table></figure>

<p>编译后，在&#x2F;home&#x2F;zk&#x2F;ai&#x2F;llama.cpp&#x2F;build&#x2F;bin下要有llama-quantize和llama-cli这两个主要文件。</p>
<h2 id="2-微调"><a href="#2-微调" class="headerlink" title="2.微调"></a>2.微调</h2><h5 id="2-1微调主代码"><a href="#2-1微调主代码" class="headerlink" title="2.1微调主代码"></a>2.1微调主代码</h5><p>这里把基础模型和数据集都改写成本地调用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> FastLanguageModel</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> SFTTrainer</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">max_seq_length = <span class="number">2048</span></span><br><span class="line">dtype = <span class="literal">None</span></span><br><span class="line">load_in_4bit = <span class="literal">True</span></span><br><span class="line">model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">    model_name = <span class="string">&quot;/home/zk/ai/base_model/llama-3-8b-bnb-4bit&quot;</span>,</span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    dtype = dtype,</span><br><span class="line">    load_in_4bit = load_in_4bit,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备训练数据</span></span><br><span class="line">alpaca_prompt = <span class="string">&quot;&quot;&quot;Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.</span></span><br><span class="line"><span class="string">### Instruction：</span></span><br><span class="line"><span class="string">&#123;&#125;</span></span><br><span class="line"><span class="string">### Input:</span></span><br><span class="line"><span class="string">&#123;&#125;</span></span><br><span class="line"><span class="string">### Response:</span></span><br><span class="line"><span class="string">&#123;&#125;&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">EOS_TOKEN = tokenizer.eos_token  <span class="comment"># 必须添加 EOS_TOKEN</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">formatting_prompts_func</span>(<span class="params">examples</span>):</span><br><span class="line">    instructions = examples[<span class="string">&quot;instruction&quot;</span>]</span><br><span class="line">    inputs = examples[<span class="string">&quot;input&quot;</span>]</span><br><span class="line">    outputs = examples[<span class="string">&quot;output&quot;</span>]</span><br><span class="line">    texts = []</span><br><span class="line">    <span class="keyword">for</span> instruction, <span class="built_in">input</span>, output <span class="keyword">in</span> <span class="built_in">zip</span>(instructions, inputs, outputs):</span><br><span class="line">        <span class="comment"># 必须添加EOS_TOKEN，否则无限生成</span></span><br><span class="line">        text = alpaca_prompt.<span class="built_in">format</span>(instruction, <span class="built_in">input</span>, output) + EOS_TOKEN</span><br><span class="line">        texts.append(text)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;text&quot;</span>: texts&#125;</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 本地数据集</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;json&quot;</span>, data_files = <span class="string">&quot;/home/zk/ai/dataset/caishui_2011_100hao.json&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(formatting_prompts_func, batched = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置训练参数</span></span><br><span class="line">model = FastLanguageModel.get_peft_model(</span><br><span class="line">    model,</span><br><span class="line">    r = <span class="number">16</span>,</span><br><span class="line">    target_modules = [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;k_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>, <span class="string">&quot;o_proj&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;gate_proj&quot;</span>, <span class="string">&quot;up_proj&quot;</span>, <span class="string">&quot;down_proj&quot;</span>, ],</span><br><span class="line">    lora_alpha = <span class="number">16</span>,</span><br><span class="line">    lora_dropout = <span class="number">0</span>,</span><br><span class="line">    bias = <span class="string">&quot;none&quot;</span>,</span><br><span class="line">    use_gradient_checkpointing = <span class="literal">True</span>,</span><br><span class="line">    random_state = <span class="number">3407</span>,</span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    use_rslora = <span class="literal">False</span>,</span><br><span class="line">    loftq_config = <span class="literal">None</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = SFTTrainer(</span><br><span class="line">    model = model,</span><br><span class="line">    train_dataset = dataset,</span><br><span class="line">    dataset_text_field = <span class="string">&quot;text&quot;</span>,</span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    tokenizer = tokenizer,</span><br><span class="line">    args = TrainingArguments(</span><br><span class="line">        per_device_train_batch_size = <span class="number">1</span>,</span><br><span class="line">        gradient_accumulation_steps = <span class="number">4</span>,</span><br><span class="line">        warmup_steps = <span class="number">2</span>,</span><br><span class="line">        max_steps = <span class="number">20</span>,</span><br><span class="line">        fp16 = <span class="keyword">not</span> torch.cuda.is_bf16_supported(),</span><br><span class="line">        bf16 = torch.cuda.is_bf16_supported(),</span><br><span class="line">        logging_steps = <span class="number">1</span>,</span><br><span class="line">        output_dir = <span class="string">&quot;outputs&quot;</span>,</span><br><span class="line">        optim = <span class="string">&quot;adamw_8bit&quot;</span>,</span><br><span class="line">        weight_decay = <span class="number">0.01</span>,</span><br><span class="line">        lr_scheduler_type = <span class="string">&quot;linear&quot;</span>,</span><br><span class="line">        seed = <span class="number">3407</span>,</span><br><span class="line">        learning_rate = <span class="number">2e-5</span>,</span><br><span class="line">    ),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line">trainer.train()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存微调模型</span></span><br><span class="line">model.save_pretrained(<span class="string">&quot;lora_model&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项：保存为16位hf模型</span></span><br><span class="line">save_16bit = <span class="built_in">input</span>(<span class="string">&quot;是否保存为16位hf模型？(y/n): &quot;</span>)</span><br><span class="line"><span class="keyword">if</span> save_16bit.lower() == <span class="string">&quot;y&quot;</span>:</span><br><span class="line">    model.save_pretrained_merged(<span class="string">&quot;outputs&quot;</span>, tokenizer, save_method=<span class="string">&quot;merged_16bit&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项：保存为gguf模型</span></span><br><span class="line">save_gguf = <span class="built_in">input</span>(<span class="string">&quot;是否保存为gguf模型？(y/n): &quot;</span>)</span><br><span class="line"><span class="keyword">if</span> save_gguf.lower() == <span class="string">&quot;y&quot;</span>:</span><br><span class="line">    os.system(<span class="string">&quot;python /home/zk/ai/llama.cpp/convert_hf_to_gguf.py --outfile /home/zk/ai/gguf_model/lm38b_tax_jzjt.gguf /home/zk/ai/outputs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项：量化为4位gguf模型</span></span><br><span class="line">quantize_4bit = <span class="built_in">input</span>(<span class="string">&quot;是否量化为4位gguf模型？(y/n): &quot;</span>)</span><br><span class="line"><span class="keyword">if</span> quantize_4bit.lower() == <span class="string">&quot;y&quot;</span>:</span><br><span class="line">    os.system(<span class="string">&quot;/home/zk/ai/llama.cpp/build/bin/llama-quantize /home/zk/ai/gguf_model/QWQ_tax_jzjt.gguf /home/zk/ai/gguf_model/lm38b_tax_jzjt-Q4_K_M.gguf Q4_K_M&quot;</span>)</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202511/eeae5e5cc27b/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202511/eeae5e5cc27b/" class="post-title-link" itemprop="url">AI大模型分析电影写微小说项目：基于AI的影视内容深度解析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-11-03 00:00:00" itemprop="dateCreated datePublished" datetime="2025-11-03T00:00:00+08:00">2025-11-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-12-12 13:05:08" itemprop="dateModified" datetime="2025-12-12T13:05:08+08:00">2025-12-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="电影台词智能分析工具：基于AI的影视内容深度解析"><a href="#电影台词智能分析工具：基于AI的影视内容深度解析" class="headerlink" title="电影台词智能分析工具：基于AI的影视内容深度解析"></a>电影台词智能分析工具：基于AI的影视内容深度解析</h1><h2 id="🎬-项目简介"><a href="#🎬-项目简介" class="headerlink" title="🎬 项目简介"></a>🎬 项目简介</h2><p>这是一个利用人工智能技术自动分析电影台词内容的智能工具。通过简单的文本输入，程序能够：</p>
<ul>
<li><strong>自动识别电影名称</strong>：从台词内容或文件名智能推断</li>
<li><strong>提炼经典台词</strong>：筛选最具代表性的10句精彩对白</li>
<li><strong>创作微小说</strong>：基于电影主题创作现代化改编故事</li>
<li><strong>支持长文本处理</strong>：智能分段处理超长电影台词</li>
</ul>
<h2 id="✨-核心功能"><a href="#✨-核心功能" class="headerlink" title="✨ 核心功能"></a>✨ 核心功能</h2><h3 id="🔍-智能电影分析"><a href="#🔍-智能电影分析" class="headerlink" title="🔍 智能电影分析"></a>🔍 智能电影分析</h3><ul>
<li>自动推断电影名称和基本信息</li>
<li>深度理解剧情脉络和人物关系</li>
<li>提取最具代表性的经典台词</li>
</ul>
<h3 id="📝-创意内容生成"><a href="#📝-创意内容生成" class="headerlink" title="📝 创意内容生成"></a>📝 创意内容生成</h3><ul>
<li>基于电影主题创作全新微小说</li>
<li>现代背景下的故事改编</li>
<li>保持原作风味的同时创新叙事</li>
</ul>
<h3 id="⚡-技术优势"><a href="#⚡-技术优势" class="headerlink" title="⚡ 技术优势"></a>⚡ 技术优势</h3><ul>
<li><strong>流式处理</strong>：支持超长台词分段分析</li>
<li><strong>多模型支持</strong>：兼容DeepSeek、通义千问等主流模型</li>
<li><strong>智能记忆</strong>：完整接收台词后再统一分析</li>
</ul>
<h2 id="🛠️-技术架构"><a href="#🛠️-技术架构" class="headerlink" title="🛠️ 技术架构"></a>🛠️ 技术架构</h2><h3 id="核心技术"><a href="#核心技术" class="headerlink" title="核心技术"></a>核心技术</h3><ul>
<li><strong>AI模型</strong>：DeepSeek-R1推理模型（支持思维链）</li>
<li><strong>API接口</strong>：硅基流动平台（OpenAI兼容）</li>
<li><strong>处理引擎</strong>：Python + OpenAI SDK</li>
</ul>
<h2 id="💡-代码解析"><a href="#💡-代码解析" class="headerlink" title="💡 代码解析"></a>💡 代码解析</h2><h3 id="1-智能分段处理长文本"><a href="#1-智能分段处理长文本" class="headerlink" title="1. 智能分段处理长文本"></a>1. 智能分段处理长文本</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">split_text_into_parts</span>(<span class="params">text_content, part_length=<span class="number">3000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;智能文本分段，避免截断完整句子&quot;&quot;&quot;</span></span><br><span class="line">    parts = []</span><br><span class="line">    sentences = re.split(<span class="string">r&#x27;(?&lt;=[。！？!?])&#x27;</span>, text_content)</span><br><span class="line">    </span><br><span class="line">    current_part = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(current_part) + <span class="built_in">len</span>(sentence) &lt;= part_length:</span><br><span class="line">            current_part += sentence</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> current_part:</span><br><span class="line">                parts.append(current_part)</span><br><span class="line">            current_part = sentence</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> current_part:</span><br><span class="line">        parts.append(current_part)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parts</span><br></pre></td></tr></table></figure>

<h3 id="2-电影名称提取"><a href="#2-电影名称提取" class="headerlink" title="2. 电影名称提取"></a>2. 电影名称提取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">extract_movie_name</span>(<span class="params">file_path</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;从复杂文件名中智能提取电影名称&quot;&quot;&quot;</span></span><br><span class="line">    filename = Path(file_path).stem</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 移除下载站点标记</span></span><br><span class="line">    clean_name = re.sub(<span class="string">r&#x27;^\[.*?\]&#x27;</span>, <span class="string">&#x27;&#x27;</span>, filename)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 移除分辨率、编码等信息</span></span><br><span class="line">    patterns_to_remove = [</span><br><span class="line">        <span class="string">r&#x27;\d&#123;4&#125;p&#x27;</span>,  <span class="comment"># 1080p, 720p等</span></span><br><span class="line">        <span class="string">r&#x27;BluRay&#x27;</span>, <span class="string">&#x27;DVD&#x27;</span>, <span class="string">&#x27;WEB-DL&#x27;</span>,</span><br><span class="line">        <span class="string">r&#x27;x\d&#123;3&#125;&#x27;</span>, <span class="string">&#x27;H\.?264&#x27;</span>, <span class="string">&#x27;HEVC&#x27;</span>,</span><br><span class="line">        <span class="string">r&#x27;\d&#123;4&#125;\.\d&#123;2&#125;\.\d&#123;2&#125;&#x27;</span>,  <span class="comment"># 日期</span></span><br><span class="line">        <span class="string">r&#x27;[A-Z][A-Za-z]+-?Team&#x27;</span>,  <span class="comment"># 发布组</span></span><br><span class="line">    ]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> pattern <span class="keyword">in</span> patterns_to_remove:</span><br><span class="line">        clean_name = re.sub(pattern, <span class="string">&#x27;&#x27;</span>, clean_name, flags=re.IGNORECASE)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 清理多余字符</span></span><br><span class="line">    clean_name = re.sub(<span class="string">r&#x27;[_-]+&#x27;</span>, <span class="string">&#x27; &#x27;</span>, clean_name)</span><br><span class="line">    clean_name = re.sub(<span class="string">r&#x27;\s+&#x27;</span>, <span class="string">&#x27; &#x27;</span>, clean_name).strip()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> clean_name</span><br></pre></td></tr></table></figure>

<h3 id="3-上下文记忆管理"><a href="#3-上下文记忆管理" class="headerlink" title="3. 上下文记忆管理"></a>3. 上下文记忆管理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConversationManager</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;管理多轮对话上下文&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, max_context_tokens=<span class="number">4000</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.history = []</span><br><span class="line">        <span class="variable language_">self</span>.max_tokens = max_context_tokens</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_message</span>(<span class="params">self, role, content</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;添加消息并维护上下文长度&quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.history.append(&#123;<span class="string">&quot;role&quot;</span>: role, <span class="string">&quot;content&quot;</span>: content&#125;)</span><br><span class="line">        <span class="variable language_">self</span>._trim_history()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_trim_history</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;智能修剪历史记录，保留最重要的对话&quot;&quot;&quot;</span></span><br><span class="line">        total_tokens = <span class="built_in">sum</span>(<span class="built_in">len</span>(msg[<span class="string">&quot;content&quot;</span>]) <span class="keyword">for</span> msg <span class="keyword">in</span> <span class="variable language_">self</span>.history)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> total_tokens &gt; <span class="variable language_">self</span>.max_tokens <span class="keyword">and</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.history) &gt; <span class="number">2</span>:</span><br><span class="line">            <span class="comment"># 移除最旧的非系统消息</span></span><br><span class="line">            <span class="keyword">for</span> i, msg <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.history):</span><br><span class="line">                <span class="keyword">if</span> msg[<span class="string">&quot;role&quot;</span>] != <span class="string">&quot;system&quot;</span>:</span><br><span class="line">                    removed = <span class="variable language_">self</span>.history.pop(i)</span><br><span class="line">                    total_tokens -= <span class="built_in">len</span>(removed[<span class="string">&quot;content&quot;</span>])</span><br><span class="line">                    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<h2 id="🎯-Prompt工程"><a href="#🎯-Prompt工程" class="headerlink" title="🎯 Prompt工程"></a>🎯 Prompt工程</h2><h3 id="1-分段发送策略"><a href="#1-分段发送策略" class="headerlink" title="1. 分段发送策略"></a>1. 分段发送策略</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一阶段：告知模型准备接收长内容</span></span><br><span class="line">initial_prompt = <span class="string">f&quot;&quot;&quot;我将分<span class="subst">&#123;parts_count&#125;</span>次发送电影《<span class="subst">&#123;movie_name&#125;</span>》的完整台词给你。</span></span><br><span class="line"><span class="string">请你先接收所有台词内容，不要立即分析。</span></span><br><span class="line"><span class="string">等我发送完所有部分后，我会让你开始分析。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">这是第1部分，共<span class="subst">&#123;parts_count&#125;</span>部分：</span></span><br><span class="line"><span class="string"><span class="subst">&#123;first_part&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请回复&quot;收到第1部分，等待后续内容。&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="2-格式约束技巧"><a href="#2-格式约束技巧" class="headerlink" title="2. 格式约束技巧"></a>2. 格式约束技巧</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">analysis_prompt = <span class="string">f&quot;&quot;&quot;请根据所有台词内容完成以下分析，严格按照要求的格式输出：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">电影名称：<span class="subst">&#123;movie_name&#125;</span></span></span><br><span class="line"><span class="string">经典台词：</span></span><br><span class="line"><span class="string">1. [第一句经典台词]</span></span><br><span class="line"><span class="string">2. [第二句经典台词]</span></span><br><span class="line"><span class="string">...（必须输出10句）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">微小说：[根据台词创作的300字微小说。]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">要求（重要指令）：</span></span><br><span class="line"><span class="string">1. 根据你所知道的给出该电影超级简单的介绍</span></span><br><span class="line"><span class="string">2. 经典台词要选择最具代表性、最打动人心的10句</span></span><br><span class="line"><span class="string">3. 微小说要基于所有台词的意境和主题创作，保持故事完整性</span></span><br><span class="line"><span class="string">4. 注意：不要和原电影叙事年代相同，尽量用现在的年代</span></span><br><span class="line"><span class="string">5. 记得为微小说写题目</span></span><br><span class="line"><span class="string">6. 禁止：不要输出任何评价性内容，只输出要求的格式内容</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">严格按照上述格式，不要添加额外说明！&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="3-角色设定增强效果"><a href="#3-角色设定增强效果" class="headerlink" title="3. 角色设定增强效果"></a>3. 角色设定增强效果</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;你是一位资深的电影评论家和小说作家，具有以下特点：</span></span><br><span class="line"><span class="string">1. 对电影艺术有深刻理解，能准确把握电影主题</span></span><br><span class="line"><span class="string">2. 擅长从台词中提炼精华，识别经典对白</span></span><br><span class="line"><span class="string">3. 具有出色的改编能力，能将经典故事现代化</span></span><br><span class="line"><span class="string">4. 严格遵守格式要求，输出结构清晰</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">你的任务是根据提供的电影台词，完成专业分析。&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="4-分阶段处理长文本"><a href="#4-分阶段处理长文本" class="headerlink" title="4. 分阶段处理长文本"></a>4. 分阶段处理长文本</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_staged_prompts</span>(<span class="params">movie_name, parts</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;创建分阶段的prompt序列&quot;&quot;&quot;</span></span><br><span class="line">    prompts = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 阶段1：建立上下文</span></span><br><span class="line">    prompts.append(&#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: <span class="string">f&quot;你将接收电影《<span class="subst">&#123;movie_name&#125;</span>》的完整台词，请先专心接收，不要分析。&quot;</span></span><br><span class="line">    &#125;)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 阶段2：分段发送内容</span></span><br><span class="line">    <span class="keyword">for</span> i, part <span class="keyword">in</span> <span class="built_in">enumerate</span>(parts, <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">            content = <span class="string">f&quot;开始发送《<span class="subst">&#123;movie_name&#125;</span>》台词，这是第<span class="subst">&#123;i&#125;</span>部分：\n\n<span class="subst">&#123;part&#125;</span>\n\n请确认收到。&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            content = <span class="string">f&quot;继续发送《<span class="subst">&#123;movie_name&#125;</span>》台词，第<span class="subst">&#123;i&#125;</span>部分：\n\n<span class="subst">&#123;part&#125;</span>\n\n请确认收到。&quot;</span></span><br><span class="line">        prompts.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: content&#125;)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 阶段3：分析指令</span></span><br><span class="line">    prompts.append(&#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, </span><br><span class="line">        <span class="string">&quot;content&quot;</span>: <span class="string">&quot;&quot;&quot;现在你已经接收了完整台词，请开始分析。注意以下关键要求：</span></span><br><span class="line"><span class="string">        1. 输出10句经典台词，必须编号1-10</span></span><br><span class="line"><span class="string">        2. 微小说要现代背景，300字左右</span></span><br><span class="line"><span class="string">        3. 不要评价，只输出结果&quot;&quot;&quot;</span></span><br><span class="line">    &#125;)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> prompts</span><br></pre></td></tr></table></figure>

<h2 id="📋-使用示例"><a href="#📋-使用示例" class="headerlink" title="📋 使用示例"></a>📋 使用示例</h2><p>输入电影台词文件（如《倩女幽魂2》台词）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">宁采臣：这里阴气太重，我们快走吧。</span><br><span class="line">聂小倩：公子，你可知道前世今生？</span><br></pre></td></tr></table></figure>

<p>输出分析结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">电影名称：倩女幽魂2</span><br><span class="line">经典台词：</span><br><span class="line">1. &quot;人间道，鬼道，各有各的轮回&quot;</span><br><span class="line">2. &quot;爱情如果能超越生死，那该多好&quot;</span><br><span class="line">3. ...</span><br><span class="line">微小说：《数字时代的灵异情缘》</span><br><span class="line">2024年，程序员宁晨在修复一个古老的数据库时，</span><br><span class="line">发现了一段被遗忘的AI代码&quot;小倩&quot;...</span><br></pre></td></tr></table></figure>

<h2 id="🚀-快速开始"><a href="#🚀-快速开始" class="headerlink" title="🚀 快速开始"></a>🚀 快速开始</h2><h3 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install openai</span><br></pre></td></tr></table></figure>

<h3 id="配置使用"><a href="#配置使用" class="headerlink" title="配置使用"></a>配置使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 简单三步配置</span></span><br><span class="line">API_KEY = <span class="string">&quot;您的API密钥&quot;</span></span><br><span class="line">INPUT_FILE_PATH = <span class="string">&quot;电影台词.txt&quot;</span></span><br><span class="line">MODEL_NAME = <span class="string">&quot;deepseek-ai/DeepSeek-R1&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="运行脚本"><a href="#运行脚本" class="headerlink" title="运行脚本"></a>运行脚本</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python movie_analysis.py</span><br></pre></td></tr></table></figure>

<h2 id="🎪-项目特色"><a href="#🎪-项目特色" class="headerlink" title="🎪 项目特色"></a>🎪 项目特色</h2><h3 id="🔥-技术创新点"><a href="#🔥-技术创新点" class="headerlink" title="🔥 技术创新点"></a>🔥 技术创新点</h3><ul>
<li><strong>智能上下文管理</strong>：自动维护对话历史，优化token使用</li>
<li><strong>动态prompt调整</strong>：根据输入内容自动调整指令细节</li>
<li><strong>错误恢复机制</strong>：网络异常时自动重试，保证任务完成</li>
<li><strong>进度实时反馈</strong>：流式输出让用户看到处理过程</li>
</ul>
<h3 id="🎨-Prompt设计哲学"><a href="#🎨-Prompt设计哲学" class="headerlink" title="🎨 Prompt设计哲学"></a>🎨 Prompt设计哲学</h3><ol>
<li><strong>明确指令优先</strong>：使用编号、强调等让模型准确理解</li>
<li><strong>格式强制约束</strong>：通过具体示例规范输出格式</li>
<li><strong>分阶段处理</strong>：复杂任务拆解为简单步骤</li>
<li><strong>角色代入法</strong>：赋予模型特定角色提升质量</li>
</ol>
<h2 id="🔧-应用场景"><a href="#🔧-应用场景" class="headerlink" title="🔧 应用场景"></a>🔧 应用场景</h2><h3 id="影视行业"><a href="#影视行业" class="headerlink" title="影视行业"></a>影视行业</h3><ul>
<li>剧本分析和优化建议</li>
<li>经典台词数据库建设</li>
<li>跨时代故事改编创意</li>
</ul>
<h3 id="教育研究"><a href="#教育研究" class="headerlink" title="教育研究"></a>教育研究</h3><ul>
<li>电影文学课程辅助工具</li>
<li>叙事结构分析研究</li>
<li>跨文化影视对比</li>
</ul>
<h3 id="个人兴趣"><a href="#个人兴趣" class="headerlink" title="个人兴趣"></a>个人兴趣</h3><ul>
<li>观影笔记智能整理</li>
<li>电影主题深度理解</li>
<li>创意写作灵感来源</li>
</ul>
<h2 id="📊-项目亮点"><a href="#📊-项目亮点" class="headerlink" title="📊 项目亮点"></a>📊 项目亮点</h2><ol>
<li><strong>智能化程度高</strong>：自动识别电影、分析主题、提取精华</li>
<li><strong>创作能力强</strong>：不仅能分析，还能创作全新内容</li>
<li><strong>用户体验好</strong>：一键式操作，结果清晰易懂</li>
<li><strong>扩展性强</strong>：支持多种AI模型和API平台</li>
<li><strong>实用价值大</strong>：适合影视爱好者、创作者、研究者</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202511/d66d812f3e87/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202511/d66d812f3e87/" class="post-title-link" itemprop="url">AI大模型分析电影写微小说项目：字幕文件清理工具 - Subtitle Cleaner</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-11-02 00:00:00" itemprop="dateCreated datePublished" datetime="2025-11-02T00:00:00+08:00">2025-11-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-12-12 12:55:02" itemprop="dateModified" datetime="2025-12-12T12:55:02+08:00">2025-12-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id=""><a href="#" class="headerlink" title=""></a></h1><p>一个简单高效的Python工具，用于清理ASS和SRT字幕文件，提取纯文本台词，去除所有格式标记、时间码和特效代码。</p>
<h2 id="🎯-项目简介"><a href="#🎯-项目简介" class="headerlink" title="🎯 项目简介"></a>🎯 项目简介</h2><p>在日常的视频处理、字幕制作或文本分析工作中，我们经常需要从字幕文件中提取纯文本内容。然而，原始的字幕文件包含大量的格式信息（如时间码、样式定义、特效代码等），这些信息会干扰我们对纯文本内容的使用。这个工具可以自动批量处理ASS和SRT字幕文件，提取干净的台词文本。</p>
<h2 id="✨-主要功能"><a href="#✨-主要功能" class="headerlink" title="✨ 主要功能"></a>✨ 主要功能</h2><ul>
<li><strong>支持多种格式</strong>：自动识别并处理ASS和SRT两种主流字幕格式</li>
<li><strong>智能清理</strong>：<ul>
<li>ASS文件：去除<code>[Script Info]</code>、<code>[V4 Styles]</code>、<code>Format:</code>等格式信息</li>
<li>SRT文件：去除序号、时间码行（如<code>00:00:24,290 --&gt; 00:00:27,700</code>）</li>
<li>通用处理：去除所有花括号内的特效代码（如<code>{\3c&amp;HFF8000&amp;}</code>）</li>
</ul>
</li>
<li><strong>批量处理</strong>：一键处理整个文件夹中的所有字幕文件</li>
<li><strong>编码兼容</strong>：自动检测并处理UTF-8、GBK、GB2312、UTF-16等多种编码</li>
<li><strong>保持原结构</strong>：按原始文件名生成对应的清理后文件</li>
</ul>
<h2 id="📁-项目结构"><a href="#📁-项目结构" class="headerlink" title="📁 项目结构"></a>📁 项目结构</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">subtitle-cleaner/</span><br><span class="line">├── clean_subtitles.py    # 主程序文件</span><br><span class="line">├── download_srt/         # （输入）原始字幕文件存放目录</span><br><span class="line">│   ├── video1.ass</span><br><span class="line">│   ├── video2.srt</span><br><span class="line">│   └── ...</span><br><span class="line">└── cleaned_srt/          # （输出）清理后的文本文件目录</span><br><span class="line">    ├── video1_cleaned.txt</span><br><span class="line">    ├── video2_cleaned.txt</span><br><span class="line">    └── ...</span><br></pre></td></tr></table></figure>

<h2 id="🚀-快速开始"><a href="#🚀-快速开始" class="headerlink" title="🚀 快速开始"></a>🚀 快速开始</h2><h3 id="安装要求"><a href="#安装要求" class="headerlink" title="安装要求"></a>安装要求</h3><ul>
<li>Python 3.6+</li>
<li>无需安装额外依赖库</li>
</ul>
<h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><ol>
<li><p><strong>准备文件</strong>：将所有要处理的ASS和SRT字幕文件放入<code>download_srt</code>文件夹</p>
</li>
<li><p><strong>运行脚本</strong>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python clean_subtitles.py</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>查看结果</strong>：清理后的纯文本文件将保存在<code>cleaned_srt</code>文件夹中</p>
</li>
</ol>
<h3 id="运行示例"><a href="#运行示例" class="headerlink" title="运行示例"></a>运行示例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">输入文件夹: download_srt</span><br><span class="line">输出文件夹: cleaned_srt</span><br><span class="line">开始处理字幕文件...</span><br><span class="line">已处理: example.ass -&gt; example_cleaned.txt</span><br><span class="line">生成台词: 5 行</span><br><span class="line">前几句台词:</span><br><span class="line">  1. 明朝景泰年间 宦官专权</span><br><span class="line">  2. 在京城设立十二监 十三库</span><br><span class="line">  3. 四司 八局及二十四衙门</span><br><span class="line">--------------------------------------------------</span><br><span class="line">处理完成！共处理 1 个字幕文件</span><br><span class="line">清理后的文件保存在: cleaned_srt</span><br></pre></td></tr></table></figure>

<h2 id="🔧-技术特点"><a href="#🔧-技术特点" class="headerlink" title="🔧 技术特点"></a>🔧 技术特点</h2><h3 id="ASS文件处理逻辑"><a href="#ASS文件处理逻辑" class="headerlink" title="ASS文件处理逻辑"></a>ASS文件处理逻辑</h3><ol>
<li>只提取以<code>Dialogue:</code>开头的行</li>
<li>分割并获取第10个逗号后的文本内容</li>
<li>去除所有<code>{...}</code>格式的特效代码</li>
</ol>
<h3 id="SRT文件处理逻辑"><a href="#SRT文件处理逻辑" class="headerlink" title="SRT文件处理逻辑"></a>SRT文件处理逻辑</h3><ol>
<li>跳过纯数字的序号行</li>
<li>跳过包含<code>--&gt;</code>的时间码行</li>
<li>保留纯文本台词行，同样去除特效代码</li>
</ol>
<h3 id="编码处理机制"><a href="#编码处理机制" class="headerlink" title="编码处理机制"></a>编码处理机制</h3><p>脚本会自动尝试多种编码格式读取文件：</p>
<ul>
<li>UTF-8</li>
<li>GBK</li>
<li>GB2312</li>
<li>UTF-16</li>
</ul>
<h2 id="💡-应用场景"><a href="#💡-应用场景" class="headerlink" title="💡 应用场景"></a>💡 应用场景</h2><ol>
<li><strong>视频内容分析</strong>：提取视频对话用于文本分析</li>
<li><strong>字幕翻译辅助</strong>：获取干净文本进行翻译</li>
<li><strong>学习笔记制作</strong>：从教学视频中提取讲解内容</li>
<li><strong>内容摘要生成</strong>：基于字幕文本生成视频摘要</li>
<li><strong>语音识别校对</strong>：对比语音识别结果与原始字幕</li>
</ol>
<h2 id="📝-代码示例"><a href="#📝-代码示例" class="headerlink" title="📝 代码示例"></a>📝 代码示例</h2><p>核心清理函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">clean_srt_content</span>(<span class="params">content</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;清理SRT字幕文件内容&quot;&quot;&quot;</span></span><br><span class="line">    lines = content.split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    cleaned_lines = []</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    n = <span class="built_in">len</span>(lines)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> i &lt; n:</span><br><span class="line">        line = lines[i].strip()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 跳过序号行和时间码行</span></span><br><span class="line">        <span class="keyword">if</span> line.isdigit() <span class="keyword">or</span> <span class="string">&#x27;--&gt;&#x27;</span> <span class="keyword">in</span> line:</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 保留并清理台词行</span></span><br><span class="line">        <span class="keyword">if</span> line:</span><br><span class="line">            line = re.sub(<span class="string">r&#x27;\&#123;[^&#125;]*\&#125;&#x27;</span>, <span class="string">&#x27;&#x27;</span>, line)</span><br><span class="line">            line = line.strip()</span><br><span class="line">            <span class="keyword">if</span> line:</span><br><span class="line">                cleaned_lines.append(line)</span><br><span class="line">        </span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;\n&#x27;</span>.join(cleaned_lines)</span><br></pre></td></tr></table></figure>

<h2 id="🔄-扩展性"><a href="#🔄-扩展性" class="headerlink" title="🔄 扩展性"></a>🔄 扩展性</h2><p>项目具有良好的扩展性，可以轻松添加以下功能：</p>
<ol>
<li><strong>支持更多字幕格式</strong>：如SSA、VTT等</li>
<li><strong>添加文本后处理</strong>：如去除广告词、标准化标点</li>
<li><strong>集成翻译API</strong>：自动翻译提取的文本</li>
<li><strong>导出多种格式</strong>：如JSON、CSV、Markdown</li>
</ol>
<h2 id="📊-性能特点"><a href="#📊-性能特点" class="headerlink" title="📊 性能特点"></a>📊 性能特点</h2><ul>
<li><strong>高效处理</strong>：单文件处理时间通常在毫秒级</li>
<li><strong>内存友好</strong>：逐行处理，避免大文件内存溢出</li>
<li><strong>容错性强</strong>：单个文件出错不影响其他文件处理</li>
<li><strong>日志详细</strong>：实时显示处理进度和结果预览</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">twoken</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
