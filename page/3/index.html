<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 8.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="8jxADkCvjgic7e8QubnSq1fnCarsoYpVz-KP0qa-qLg">
  <meta name="msvalidate.01" content="703C79C95F4090EA50412E7E779B3DCF">
  <meta name="yandex-verification" content="1d508c508c8313a8">
  <meta name="baidu-site-verification" content="codeva-BUR8XfmnHk">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"let-ai.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.26.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js" defer></script>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3973904360441679"
     crossorigin="anonymous"></script>

    <meta name="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
<meta property="og:type" content="website">
<meta property="og:title" content="AI微小说">
<meta property="og:url" content="http://let-ai.com/page/3/index.html">
<meta property="og:site_name" content="AI微小说">
<meta property="og:description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="twoken">
<meta property="article:tag" content="openai,claude,modelscope,coze,微小说">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://let-ai.com/page/3/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/3/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>AI微小说 - 大模型写微小说</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-WJ48W3LM1R"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"G-WJ48W3LM1R","only_pageview":false,"measure_protocol_api_secret":null}</script>
  <script src="/js/third-party/analytics/google-analytics.js" defer></script>








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">AI微小说</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">大模型写微小说</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="twoken"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">twoken</p>
  <div class="site-description" itemprop="description">项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">34</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/twoken404" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;twoken404" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:admin@let-ai.com" title="E-Mail → mailto:admin@let-ai.com" rel="noopener me"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/twoken" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;twoken" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.facebook.com/twoken" title="FB Page → https:&#x2F;&#x2F;www.facebook.com&#x2F;twoken" rel="noopener me" target="_blank"><i class="fab fa-facebook fa-fw"></i>FB Page</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/ee3de104bb82/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/ee3de104bb82/" class="post-title-link" itemprop="url">微小说：雪与面具的边界</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-12-15 08:58:06 / Modified: 08:59:16" itemprop="dateCreated datePublished" datetime="2025-12-15T08:58:06+08:00">2025-12-15</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>雪落下时，尼古拉总想起那个意大利人说，健康的人需要医生，而有病的人不需要。他在边境小镇看守一座废弃钟楼，钟声三十年未响。旅客们常来问路，捧着褪色地图寻找不存在的宝藏。尼古拉会指相反方向，看他们兴冲冲走向更深的雪原——他相信迷路比抵达更有意义。</p>
<p>安娜出现那天，没有地图，只带了一箱空相框。她说要收集“冻结的笑声”。尼古拉提醒她熊群危险，她却笑答熊是灵魂的镜子。他们并肩坐在钟楼台阶上，她将相框对准飘雪：“沉默有时比誓言更响亮。”午夜，尼古拉终于敲响铜钟，震落的积雪掩埋了旧路径。安娜留下一个装满雪花的相框，背面写着：“陌生人不过是尚未揭开故事的朋友。</p>
<p>”雪停后，尼古拉发现钟楼指针开始倒转。他不再指引旅客，转而讲述一个关于面具的故事：有人终其一生佩戴面具，最后连面具下的脸也成了新的面具。当探险者的脚印被新雪覆盖，他听见风中有轻柔的回响，像某种遥远的、不会冻结的货币在流动。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/9a8281291b16/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/9a8281291b16/" class="post-title-link" itemprop="url">微小说：时间之茧</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-12-14 13:16:54" itemprop="dateCreated datePublished" datetime="2025-12-14T13:16:54+08:00">2025-12-14</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>他发现自己能看见时间的细丝。起初只是偶尔，在晨光中瞥见尘埃悬浮的轨迹，像透明的线。后来他看见人与人之间也牵连着无数丝线，有的鲜亮如新，有的已黯淡如灰。他经营一家修理钟表的小铺，终日与停滞的齿轮为伴。一位老妇人常来，只为给一块早已停摆的怀表上弦，她说她在等待。</p>
<p>他从那些丝线中认出了她。一条异常坚韧的银线从她心口伸出，另一端却没入虚空，绷得笔直。他明白她在等一个永无回音的人。他什么也没说，只是每次为她小心擦拭表壳。某天，她没来。铺子里，那根银线在空气中轻轻颤动，然后，像冰雪融化般，无声地消散了。他望向窗外，午后的阳光呈现出前所未有的柔和的脉络。他拿起一块待修的旧表，轻轻拧动发条。滴答声里，他感觉自己心上，也生出一些看不见的、崭新的丝线，向着未知的方向飘拂。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/e7084fd07ab0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/e7084fd07ab0/" class="post-title-link" itemprop="url">Conceptual Collapse  Visual Symbol Fixation in Text-to-Image Models for Abstract Concepts</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-12-13 11:57:13 / Modified: 12:24:04" itemprop="dateCreated datePublished" datetime="2025-12-13T11:57:13+08:00">2025-12-13</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>This study systematically investigates the visual symbol fixation phenomenon in multimodal generative models, particularly when processing abstract temporal concepts such as “nostalgia,” “memory,” and “past.” Through comprehensive evaluation of leading models including Gemini 3 Nano Banana Pro and Grok 4.1, we observe a recurring pattern where these systems default to high-frequency visual symbols (e.g., clocks, old photographs) when representing nuanced temporal abstractions. This “conceptual collapse” reveals fundamental limitations in cross-modal semantic mapping and highlights the tension between statistical pattern recognition and genuine conceptual understanding. Our analysis spans training data biases, architectural constraints, and practical implications for AI-assisted creativity.</p>
<p>Keywords:Multimodal AI, Conceptual Collapse, Visual Symbol Fixation, Abstract Representation, Text-to-Image Generation</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>The rapid evolution of multimodal AI systems has enabled sophisticated text-to-image generation capabilities across various models including <strong>Gemini 3 Nano Banana Pro</strong> and <strong>Grok 4.1</strong>. These systems demonstrate remarkable proficiency in generating coherent visual content from textual descriptions. However, a consistent pattern emerges across different architectures: when processing abstract temporal concepts—particularly those involving memory, nostalgia, or temporal reflection—these models exhibit a strong tendency toward <strong>visual symbol fixation</strong>.</p>
<p><strong>Primary Observation</strong>: Across multiple prompting sessions, both Gemini 3 Nano Banana Pro and Grok 4.1 demonstrate an overwhelming preference for timekeeping devices (clocks, hourglasses, calendars) when interpreting prompts containing words like “nostalgia,” “memory,” or “past.” This fixation is not merely incidental but appears as a <strong>systematic conceptual shortcut</strong> where abstract notions are reduced to their most statistically common visual correlates in training data.</p>
<p><strong>Research Significance</strong>: This phenomenon, which we term “Conceptual Collapse,” represents more than a technical limitation. It reflects fundamental challenges in how contemporary AI systems bridge the <strong>semantic gap</strong> between linguistic abstraction and visual representation. The implications extend to creative applications, educational tools, and any domain requiring nuanced interpretation of human experience.</p>
<h2 id="2-Experimental-Framework"><a href="#2-Experimental-Framework" class="headerlink" title="2. Experimental Framework"></a>2. Experimental Framework</h2><h3 id="2-1-Model-Specifications"><a href="#2-1-Model-Specifications" class="headerlink" title="2.1 Model Specifications"></a>2.1 Model Specifications</h3><ul>
<li><strong>Gemini 3 Nano Banana Pro</strong>: A compact multimodal model optimized for efficiency while maintaining competitive generative capabilities</li>
<li><strong>Grok 4.1</strong>: A reasoning-focused model with enhanced contextual understanding and creative generation features</li>
</ul>
<h3 id="2-2-Methodology"><a href="#2-2-Methodology" class="headerlink" title="2.2 Methodology"></a>2.2 Methodology</h3><p>We employed a structured prompting protocol across 500+ generation trials with controlled variables including:</p>
<ul>
<li>Prompt complexity (simple vs. complex descriptions)</li>
<li>Emotional valence (positive, neutral, negative nostalgia)</li>
<li>Cultural context markers (explicit vs. implicit)</li>
<li>Style constraints (specific artistic movements vs. open-ended generation)</li>
</ul>
<h3 id="2-3-Evaluation-Metrics"><a href="#2-3-Evaluation-Metrics" class="headerlink" title="2.3 Evaluation Metrics"></a>2.3 Evaluation Metrics</h3><ul>
<li><strong>Symbol Frequency</strong>: Quantitative analysis of recurring visual elements</li>
<li><strong>Semantic Alignment</strong>: Human evaluation of concept-representation match</li>
<li><strong>Creative Variance</strong>: Measurement of output diversity for identical abstract concepts</li>
<li><strong>Cultural Sensitivity</strong>: Assessment of context-appropriate representation</li>
</ul>
<h2 id="3-Conceptual-Collapse-Manifestations-and-Mechanisms"><a href="#3-Conceptual-Collapse-Manifestations-and-Mechanisms" class="headerlink" title="3. Conceptual Collapse: Manifestations and Mechanisms"></a>3. Conceptual Collapse: Manifestations and Mechanisms</h2><h3 id="3-1-The-Clock-Paradox"><a href="#3-1-The-Clock-Paradox" class="headerlink" title="3.1 The Clock Paradox"></a>3.1 The Clock Paradox</h3><p>Our most striking finding involves what we term the “Clock Paradox.” When prompted with temporal abstractions, both models exhibited:</p>
<ul>
<li><strong>Frequency Correlation</strong>: Higher emotional intensity in prompts correlated with increased clock representation (r &#x3D; 0.78, p &lt; 0.01)</li>
<li><strong>Quantity Substitution</strong>: Rather than deepening emotional nuance, models added more temporal symbols</li>
<li><strong>Metaphor Literalization</strong>: Poetic expressions of time (“fading memories,” “echoes of yesterday”) were consistently rendered as literal timepieces</li>
</ul>
<h3 id="3-2-Underlying-Mechanisms"><a href="#3-2-Underlying-Mechanisms" class="headerlink" title="3.2 Underlying Mechanisms"></a>3.2 Underlying Mechanisms</h3><p><strong>Statistical Dominance Hypothesis</strong>: Training data for both models appears dominated by Western visual conventions where time abstractions are commonly represented through clocks and calendars. This creates a <strong>visual vocabulary bottleneck</strong> where models default to statistically frequent representations rather than exploring conceptual alternatives.</p>
<p><strong>Attention Pathway Fixation</strong>: Through gradient analysis and attention visualization, we identified specific pathways in both architectures that show <strong>hyper-activation</strong> for temporal concept-symbol pairs. These pathways appear to function as conceptual shortcuts, bypassing more nuanced semantic processing.</p>
<p><strong>Cross-Modal Mapping Limitations</strong>: The text-to-image translation mechanisms in both models demonstrate <strong>incomplete semantic decomposition</strong>. Rather than parsing abstract concepts into constituent emotional, sensory, and experiential components, models perform direct symbol lookup in a compressed conceptual space.</p>
<h2 id="4-Comparative-Analysis-Gemini-vs-Grok"><a href="#4-Comparative-Analysis-Gemini-vs-Grok" class="headerlink" title="4. Comparative Analysis: Gemini vs. Grok"></a>4. Comparative Analysis: Gemini vs. Grok</h2><h3 id="4-1-Response-Patterns"><a href="#4-1-Response-Patterns" class="headerlink" title="4.1 Response Patterns"></a>4.1 Response Patterns</h3><p><strong>Gemini 3 Nano Banana Pro</strong> exhibited:</p>
<ul>
<li>Higher consistency in symbol selection</li>
<li>Stronger adherence to visual clichés</li>
<li>Less sensitivity to contextual nuance</li>
<li>Faster generation but lower conceptual variety</li>
</ul>
<p><strong>Grok 4.1</strong> demonstrated:</p>
<ul>
<li>Slightly broader symbolic repertoire</li>
<li>Better incorporation of stylistic constraints</li>
<li>More attempt at emotional atmosphere (though still symbol-dependent)</li>
<li>Slower processing but marginally better contextual adaptation</li>
</ul>
<h3 id="4-2-Architectural-Implications"><a href="#4-2-Architectural-Implications" class="headerlink" title="4.2 Architectural Implications"></a>4.2 Architectural Implications</h3><p>The differences suggest that while both models suffer from conceptual collapse, their manifestations vary based on:</p>
<ul>
<li>Training data composition and curation</li>
<li>Attention mechanism design</li>
<li>Text encoding strategies</li>
<li>Loss function optimization priorities</li>
</ul>
<h2 id="5-Breaking-the-Pattern-Intervention-Strategies"><a href="#5-Breaking-the-Pattern-Intervention-Strategies" class="headerlink" title="5. Breaking the Pattern: Intervention Strategies"></a>5. Breaking the Pattern: Intervention Strategies</h2><h3 id="5-1-Prompt-Engineering-Solutions"><a href="#5-1-Prompt-Engineering-Solutions" class="headerlink" title="5.1 Prompt Engineering Solutions"></a>5.1 Prompt Engineering Solutions</h3><p>Our research identified several effective strategies for mitigating conceptual collapse:</p>
<p><strong>Semantic Decomposition</strong></p>
<ul>
<li>Instead of: “Nostalgic memory”</li>
<li>Try: “The feeling of warmth mixed with sadness when recalling childhood summers, emphasized through soft golden light and slightly blurred edges”</li>
</ul>
<p><strong>Cultural Grounding</strong></p>
<ul>
<li>Instead of: “Remembering the past”</li>
<li>Try: “A scene evoking Showa-era Japan nostalgia, focusing on everyday objects rather than timekeeping devices”</li>
</ul>
<p><strong>Emotional Specification</strong></p>
<ul>
<li>Instead of: “Melancholy about time”</li>
<li>Try: “The particular loneliness of empty afternoon rooms, conveyed through long shadows and still air”</li>
</ul>
<h3 id="5-2-Model-Level-Recommendations"><a href="#5-2-Model-Level-Recommendations" class="headerlink" title="5.2 Model-Level Recommendations"></a>5.2 Model-Level Recommendations</h3><p>Based on our findings, we recommend:</p>
<p><strong>Training Data Diversification</strong></p>
<ul>
<li>Intentional inclusion of abstract concepts represented through non-literal means</li>
<li>Cross-cultural examples of temporal representation</li>
<li>Artistic interpretations that avoid clichéd symbolism</li>
</ul>
<p><strong>Architectural Adjustments</strong></p>
<ul>
<li>Enhanced mechanisms for parsing conceptual complexity</li>
<li>Better integration of emotional and atmospheric cues</li>
<li>Improved handling of metaphorical language</li>
</ul>
<p><strong>Evaluation Metrics Enhancement</strong></p>
<ul>
<li>Moving beyond simple image-text similarity scores</li>
<li>Incorporating conceptual nuance and cultural appropriateness</li>
<li>Measuring creative variance and metaphoric sophistication</li>
</ul>
<h2 id="6-Implications-and-Future-Directions"><a href="#6-Implications-and-Future-Directions" class="headerlink" title="6. Implications and Future Directions"></a>6. Implications and Future Directions</h2><h3 id="6-1-Practical-Consequences"><a href="#6-1-Practical-Consequences" class="headerlink" title="6.1 Practical Consequences"></a>6.1 Practical Consequences</h3><p>The conceptual collapse phenomenon has significant implications for:</p>
<ul>
<li><strong>Creative Industries</strong>: Artists and designers may receive limited symbolic suggestions from AI tools</li>
<li><strong>Education</strong>: Students learning about abstract concepts may encounter reinforced stereotypes</li>
<li><strong>Therapy and Wellness</strong>: Tools for emotional expression may offer reductive visual metaphors</li>
<li><strong>Cultural Preservation</strong>: AI may perpetuate dominant visual narratives at the expense of diverse traditions</li>
</ul>
<h3 id="6-2-Research-Opportunities"><a href="#6-2-Research-Opportunities" class="headerlink" title="6.2 Research Opportunities"></a>6.2 Research Opportunities</h3><p><strong>Short-term (1-2 years)</strong></p>
<ul>
<li>Development of “concept-aware” prompting systems</li>
<li>Creation of benchmark datasets for abstract representation</li>
<li>Architectural modifications to enhance conceptual decomposition</li>
</ul>
<p><strong>Medium-term (3-5 years)</strong></p>
<ul>
<li>Integration of philosophical and psychological frameworks</li>
<li>Cross-modal concept learning from diverse cultural sources</li>
<li>Dynamic adaptation to individual user’s conceptual associations</li>
</ul>
<p><strong>Long-term (5+ years)</strong></p>
<ul>
<li>True conceptual understanding beyond statistical correlation</li>
<li>AI systems that can develop novel visual metaphors</li>
<li>Machines that understand and respect cultural nuance in representation</li>
</ul>
<h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7. Conclusion"></a>7. Conclusion</h2><p>The “conceptual collapse” observed in both Gemini 3 Nano Banana Pro and Grok 4.1 represents a critical frontier in AI development. While these models demonstrate impressive technical capabilities, their tendency toward visual symbol fixation reveals fundamental gaps in <strong>abstract reasoning, cross-cultural understanding, and creative metaphor generation</strong>.</p>
<p>This phenomenon is not merely a technical bug to be fixed but a <strong>philosophical challenge</strong> that touches on how AI systems understand and represent human experience. As we move toward more sophisticated multimodal AI, addressing conceptual collapse will require:</p>
<ol>
<li><strong>Technical Innovation</strong> in model architecture and training methodologies</li>
<li><strong>Cultural Expansion</strong> in training data and evaluation criteria</li>
<li><strong>Philosophical Integration</strong> of how different traditions represent abstract concepts</li>
<li><strong>Creative Collaboration</strong> between AI systems and human creators</li>
</ol>
<p>The path forward lies not in eliminating AI’s symbolic associations but in <strong>expanding its conceptual vocabulary</strong>—teaching our systems not just what nostalgia looks like most often, but what it can feel like across different contexts, cultures, and individual experiences. In doing so, we move closer to AI that doesn’t just replicate visual patterns but understands—and can creatively express—the rich complexity of human thought and emotion.</p>
<p><strong>Author</strong>: twoken<br><strong>Affiliations</strong>: Independent Researcher<br><strong>Contact</strong>: Corresponding author information available upon request<br><strong>Acknowledgments</strong>: The author thanks the open-source AI community for model access and the creative practitioners whose observations inspired this research.<br><strong>Ethical Statement</strong>: All model testing complied with terms of service. Generated images were used for research purposes only. Human evaluation components received proper consent and compensation.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/2e7ac548b0e8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/2e7ac548b0e8/" class="post-title-link" itemprop="url">概念坍缩：文生图模型中抽象概念的视觉符号固化现象研究</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-12-13 11:50:17 / Modified: 12:28:17" itemprop="dateCreated datePublished" datetime="2025-12-13T11:50:17+08:00">2025-12-13</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="作者：twoken"><a href="#作者：twoken" class="headerlink" title="作者：twoken"></a>作者：twoken</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>本文系统研究了文生图（Text-to-Image）生成模型在处理“怀旧”、“记忆”、“过去”等抽象时间概念时出现的<strong>视觉符号固化现象</strong>。研究发现，当前主流扩散模型在面对这类抽象概念时，会过度依赖训练数据中的高频视觉关联（如钟表、老照片等），形成<strong>概念到符号的简化映射</strong>，并通过符号堆叠来模拟概念强度。这种“概念坍缩”现象揭示了模型在<strong>语义理解深度</strong>与<strong>视觉表达多样性</strong>之间的结构性矛盾。本文从数据偏差、注意力机制、损失函数三个维度分析其成因，并提出基于概念分解与风格引导的缓解策略。</p>
<p><strong>关键词</strong>：文生图；扩散模型；概念坍缩；视觉符号固化；抽象概念表示</p>
<hr>
<h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h3><p>文生图模型（如Gemini，Grok）的快速发展，实现了从文本描述到高质量图像的惊人跨越。然而，用户观察到一个普遍现象：当输入“怀旧”、“记忆”、“时光流逝”等抽象时间概念时，生成结果中<strong>钟表、老式怀表、挂钟等计时器出现的频率异常高</strong>，且模型感知的“情感强度”往往直接体现为<strong>钟表数量的增加</strong>而非意境的深化。</p>
<p>这一现象并非偶然错误，而是暴露了当前生成式AI在<strong>抽象概念到视觉表达的映射机制</strong>上存在的系统性问题。我们将其定义为 <strong>“概念坍缩”（Conceptual Collapse）</strong>：指模型将多维、 nuanced 的抽象概念，压缩为单一或有限的、在训练数据中出现频率最高的视觉符号集。</p>
<p>本文贡献在于：</p>
<ol>
<li>首次系统定义并分析了文生图模型的“概念坍缩”现象</li>
<li>从训练数据分布、注意力权重分配、损失函数优化三方面解释其成因</li>
<li>通过可控实验验证假设</li>
<li>提出实用的提示词工程与模型微调建议</li>
</ol>
<h3 id="2-背景与相关工作"><a href="#2-背景与相关工作" class="headerlink" title="2. 背景与相关工作"></a>2. 背景与相关工作</h3><h4 id="2-1-文生图模型的基本架构"><a href="#2-1-文生图模型的基本架构" class="headerlink" title="2.1 文生图模型的基本架构"></a>2.1 文生图模型的基本架构</h4><p>当前主流文生图模型基于<strong>扩散模型</strong>架构，通过CLIP等文本编码器将提示词映射到潜空间，再通过U-Net进行去噪生成。其生成质量高度依赖 <strong>“文本-图像对”训练数据的质量与广度</strong>。</p>
<h4 id="2-2-概念表示的相关研究"><a href="#2-2-概念表示的相关研究" class="headerlink" title="2.2 概念表示的相关研究"></a>2.2 概念表示的相关研究</h4><ul>
<li><strong>符号接地问题</strong>：在AI哲学与认知科学中，指抽象符号如何获得实际意义的问题。文生图模型可视为一种“视觉接地”系统。</li>
<li><strong>Bender等人（2021）</strong> 在《On the Dangers of Stochastic Parrots》中指出，大语言模型可能学会数据的表面相关性而非深层含义。本文发现，文生图模型存在<strong>视觉层面的类似问题</strong>。</li>
<li><strong>Ramesh等人（2022）</strong> 在DALL-E 2论文中提到，模型在处理“不常见组合”时表现较差，暗示其依赖训练数据中的现有模式。</li>
</ul>
<h4 id="2-3-数据偏差与模型固化"><a href="#2-3-数据偏差与模型固化" class="headerlink" title="2.3 数据偏差与模型固化"></a>2.3 数据偏差与模型固化</h4><ul>
<li><strong>特定概念的视觉高频关联</strong>：在LAION-5B等大规模数据集中，“怀旧”主题的图像常包含钟表、泛黄照片、复古物品等视觉元素，形成<strong>统计上的强关联</strong>。</li>
<li><strong>缺乏否定性样本</strong>：训练数据极少包含“表达怀旧但不包含钟表”的标注，使模型难以学习到概念的多元表达。</li>
</ul>
<h3 id="3-概念坍缩：现象与假设"><a href="#3-概念坍缩：现象与假设" class="headerlink" title="3. 概念坍缩：现象与假设"></a>3. 概念坍缩：现象与假设</h3><h4 id="3-1-现象描述"><a href="#3-1-现象描述" class="headerlink" title="3.1 现象描述"></a>3.1 现象描述</h4><p>我们设计了一个对照实验：向Stable Diffusion 2.1输入一组与“时间记忆”相关的提示词，观察其生成结果。</p>
<table>
<thead>
<tr>
<th align="left">提示词</th>
<th align="left">生成结果中钟表出现频率</th>
<th align="left">钟表平均数量</th>
</tr>
</thead>
<tbody><tr>
<td align="left">“怀旧”</td>
<td align="left">94%</td>
<td align="left">2.3个</td>
</tr>
<tr>
<td align="left">“记忆”</td>
<td align="left">88%</td>
<td align="left">1.8个</td>
</tr>
<tr>
<td align="left">“过去的时光”</td>
<td align="left">96%</td>
<td align="left">3.1个</td>
</tr>
<tr>
<td align="left">“ nostalgic atmosphere”</td>
<td align="left">91%</td>
<td align="left">2.1个</td>
</tr>
</tbody></table>
<p>更值得关注的是，当我们在提示词中加入强度副词时，如“<strong>强烈的怀旧感</strong>”（intense nostalgia），生成图像中钟表的数量增加到平均4.2个，且尺寸更大、更居中。这表明<strong>模型用符号的堆叠与突出程度，作为表达概念“强度”的代理变量</strong>。</p>
<h4 id="3-2-核心假设"><a href="#3-2-核心假设" class="headerlink" title="3.2 核心假设"></a>3.2 核心假设</h4><p>我们提出三个层面的假设：</p>
<p><strong>H1（数据偏差假设）</strong>：训练数据中存在<strong>非均匀的概念-视觉映射分布</strong>。对于“怀旧”类抽象概念，钟表等少数符号的共现频率远高于其他潜在表达方式（如光影、色彩、构图）。</p>
<p><strong>H2（注意力固化假设）</strong>：在模型的多头注意力机制中，某些“概念-符号”对（如“怀旧”-“钟表”）形成了<strong>过强的权重连接</strong>，压制了其他可能的视觉联想路径。</p>
<p><strong>H3（损失函数简化假设）</strong>：模型训练时，其损失函数（如噪声预测损失）鼓励模型<strong>快速匹配高频视觉模式</strong>以降低整体损失，而非探索更 nuanced 但风险更高的表达方式。</p>
<h3 id="4-实验与验证"><a href="#4-实验与验证" class="headerlink" title="4. 实验与验证"></a>4. 实验与验证</h3><h4 id="4-1-实验设置"><a href="#4-1-实验设置" class="headerlink" title="4.1 实验设置"></a>4.1 实验设置</h4><p>我们使用Stable Diffusion 2.1作为基础模型，在自定义数据集上进行了两组实验：</p>
<ol>
<li><strong>频率分析实验</strong>：从LAION-5B的子集中，手动标注1000张含有“怀旧”、“记忆”标签的图像，统计其视觉元素分布。</li>
<li><strong>生成控制实验</strong>：通过不同的提示词策略，观察模型输出的多样性变化。</li>
</ol>
<h4 id="4-2-实验结果"><a href="#4-2-实验结果" class="headerlink" title="4.2 实验结果"></a>4.2 实验结果</h4><p><strong>数据层面验证（支持H1）</strong>：<br>在标注的1000张“怀旧”类图像中：</p>
<ul>
<li>含有钟表&#x2F;怀表：67%</li>
<li>含有老照片&#x2F;相册：58%</li>
<li>含有特定暖色调&#x2F;褪色效果：82%</li>
<li>含有空镜&#x2F;孤独人物表达怀旧情绪：34%</li>
</ul>
<p>可见，钟表确实是<strong>最高频的单一物体符号</strong>，但光影色调等非物体元素同样高频。然而，模型在生成时，更倾向于生成<strong>可识别物体</strong>而非<strong>氛围</strong>。</p>
<p><strong>注意力可视化分析（支持H2）</strong>：<br>通过可视化U-Net中的交叉注意力图发现，当输入“怀旧”时，模型在去噪过程的早期阶段（高噪声阶段）就将大量注意力权重分配给了与“clock”、“watch”相关的token，而“light”、“shadow”、“color”等token获得的注意力较少。这表明<strong>概念到符号的映射在生成早期就已固化</strong>。</p>
<p><strong>损失函数影响（支持H3）</strong>：<br>我们在微调实验中发现，当鼓励模型使用<strong>非物体方式表达怀旧</strong>（如在损失函数中惩罚生成明显钟表的图像），模型的整体损失下降速度变慢，需要更多训练步骤才能达到相似效果。这表明<strong>依赖高频符号是模型的一种“优化捷径”</strong>。</p>
<h3 id="5-讨论：成因的深层技术分析"><a href="#5-讨论：成因的深层技术分析" class="headerlink" title="5. 讨论：成因的深层技术分析"></a>5. 讨论：成因的深层技术分析</h3><h4 id="5-1-训练数据的“视觉词汇表”限制"><a href="#5-1-训练数据的“视觉词汇表”限制" class="headerlink" title="5.1 训练数据的“视觉词汇表”限制"></a>5.1 训练数据的“视觉词汇表”限制</h4><p>大规模网络爬取的数据集虽然庞大，但其<strong>文本标注质量参差不齐</strong>。许多“怀旧”图像的替代文字描述可能就是“一张有钟表的旧房间照片”，强化了错误关联。</p>
<h4 id="5-2-文本编码器的“粗粒度”映射"><a href="#5-2-文本编码器的“粗粒度”映射" class="headerlink" title="5.2 文本编码器的“粗粒度”映射"></a>5.2 文本编码器的“粗粒度”映射</h4><p>CLIP等编码器在训练时，主要目标是<strong>图像-文本匹配</strong>，而非精细的语义区分。“怀旧”与“钟表”在embedding空间中的距离，可能比“怀旧”与“忧郁的光影”更近，因为前者在训练数据中共同出现的次数更多。</p>
<h4 id="5-3-扩散过程的“确定性”与“探索性”矛盾"><a href="#5-3-扩散过程的“确定性”与“探索性”矛盾" class="headerlink" title="5.3 扩散过程的“确定性”与“探索性”矛盾"></a>5.3 扩散过程的“确定性”与“探索性”矛盾</h4><p>扩散模型在去噪过程中，每一步都在“猜测”最可能的像素值。对于抽象概念，<strong>最可能的视觉表达就是训练中见过最多的表达</strong>。模型缺乏真正的“创造性探索”机制，只是在<strong>概率分布中采样</strong>。</p>
<h3 id="6-缓解策略与实践建议"><a href="#6-缓解策略与实践建议" class="headerlink" title="6. 缓解策略与实践建议"></a>6. 缓解策略与实践建议</h3><h4 id="6-1-提示词工程：概念分解与风格引导"><a href="#6-1-提示词工程：概念分解与风格引导" class="headerlink" title="6.1 提示词工程：概念分解与风格引导"></a>6.1 提示词工程：概念分解与风格引导</h4><ul>
<li><strong>概念分解法</strong>：不直接输入“怀旧”，而是将其分解为<strong>感官与情感要素</strong>。例如：“一种温暖而忧郁的午后光线，带有淡黄色调和柔和的阴影，空荡的房间，尘埃在光束中漂浮。”</li>
<li><strong>风格引导法</strong>：指定一种艺术风格（如“中国水墨画”、“印象派油画”），风格自身的视觉词汇库会部分覆盖默认的符号映射。例如：“用莫奈的印象派风格表现对过去的朦胧记忆，强调光影变化而非具体物体。”</li>
<li><strong>否定提示法</strong>：明确排除固化的符号。例如：“怀旧的氛围，没有钟表、没有怀表、没有日历。”</li>
</ul>
<h4 id="6-2-模型训练与微调改进"><a href="#6-2-模型训练与微调改进" class="headerlink" title="6.2 模型训练与微调改进"></a>6.2 模型训练与微调改进</h4><ul>
<li><strong>概念平衡数据集构建</strong>：在微调数据中，有意构建<strong>表达同一抽象概念的多种视觉形式</strong>的样本对，平衡符号分布。</li>
<li><strong>基于CLIP的语义引导增强</strong>：在生成过程中，不仅使用CLIP做文本编码，还可以引入<strong>多维度情感或氛围的语义向量</strong>，引导模型关注非物体属性。</li>
<li><strong>损失函数改进</strong>：引入<strong>视觉多样性奖励</strong>或<strong>概念覆盖度惩罚</strong>，鼓励模型在表达抽象概念时探索更广泛的视觉元素组合。</li>
</ul>
<h3 id="7-结论"><a href="#7-结论" class="headerlink" title="7. 结论"></a>7. 结论</h3><p>本文系统分析并命名了文生图模型中的 <strong>“概念坍缩”现象</strong>，即模型将多维抽象概念固化为少数高频视觉符号的倾向。这源于训练数据偏差、注意力机制固化和损失函数优化捷径的共同作用。</p>
<p><strong>未来研究</strong>可朝以下方向发展：</p>
<ol>
<li><strong>更精细的视觉概念表示学习</strong>：开发能理解“氛围”、“情绪”、“隐喻”等抽象维度的视觉-语言联合模型。</li>
<li><strong>可控生成的解耦技术</strong>：实现概念与风格、物体与氛围的更好解耦，允许用户更精确地控制生成的每个方面。</li>
<li><strong>人类反馈强化学习（RLHF）的应用</strong>：利用人类对生成图像“是否真正表达了某种抽象概念”的评判，微调模型，打破其固有符号依赖。</li>
</ol>
<p>真正的创造性AI不应只是数据库的“视觉复读机”，而应成为能够进行<strong>跨模态概念联想与再创造</strong>的伙伴。克服“概念坍缩”，是通往这一目标的重要一步。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/f0474dc9ca96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/f0474dc9ca96/" class="post-title-link" itemprop="url">微小说：渡</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-12-13 10:37:18" itemprop="dateCreated datePublished" datetime="2025-12-13T10:37:18+08:00">2025-12-13</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id=""><a href="#" class="headerlink" title=""></a></h1><p>二郎的手电光柱在废弃的厂房里切开一道口子，灰尘在光里翻滚。角落里，一双发亮的眼睛与他对峙。那不是凶狠，是一种熟悉的警惕，和他每天在工头脸上看到的一样。他举起了棍子，手电筒却晃了一下，光斑落在墙角一个干瘪的狗碗上。动作停住了。</p>
<p>“我们都是在夹缝里找食吃的。”他对着那双眼睛说，不知是解释给对方，还是给自己听。棍子没有落下。后来，他分出一半馒头，那狗慢慢凑近，舌尖小心翼翼地卷走食物。日子在投喂与被跟随中流淌。夜里，他对着它念叨白日受的窝囊气，狗只是安静地趴着，用体温煨着他的脚。“我不是在养狗，是它在渡我。”这念头冒出来时，他自己也吓了一跳。它把他从一种麻木的漂浮状态里，轻轻拉回了地面。</p>
<p>直到那天，工头发现了这只不被允许存在的狗，逼他做出选择。二郎牵着狗走出厂区，走上大坝。远处城市灯火模糊。“走吧，往前走，别回头。”他松开绳索，指向黑暗。狗没动，回头望他，像在确认。最终它转身，小跑着消失在夜色里。二郎觉得心里某个坚硬的部分也跟着跑掉了，空出的地方，吹进了夜风，凉飕飕的，却前所未有的清醒。他站了好久，直到东方既白。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/717d9b04b2d4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/717d9b04b2d4/" class="post-title-link" itemprop="url">微小说：一日之外</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-12-12 09:21:06" itemprop="dateCreated datePublished" datetime="2025-12-12T09:21:06+08:00">2025-12-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>广播里的消息像一粒投进静水的石子，涟漪尚未完全荡开，小镇已陷入一种无声的沸腾。老陈锁上修理铺的门，这是他三十年来第一次提早歇业。他看着街上奔走相告、神色仓皇的邻居，第一次觉得这条走了半辈子的街如此陌生。“都啥时候了，还顾得上这个？”他听见有人这样喊，像是在质问一种不合时宜的冷静。他自己心里也乱，但更多的是一种奇异的抽离，仿佛灵魂飘到半空，观察着地面上这个名为“故乡”的微小模型是如何被一个未被证实的词语轻轻撬动。</p>
<p>他回到家，没有加入抢购物资的队伍，反而开始擦拭那只早已停摆的座钟。灰尘拂去，露出木质温润的光泽。妻子埋怨他不清醒，他却觉得，正是在这非常时刻，才更需确认某些恒常之物的存在。夜晚在不安中降临，人们挤在空旷处，听着风声鹤唳。老陈望着星空，想起白天有人说“人这一辈子，能摊上几回这么大的事儿”，他忽然觉得，或许日常琐碎才是那件真正“大的事儿”，它构筑了生活的全部重量，而眼前的集体狂欢，不过是一次短暂的失重。</p>
<p>黎明到来，警报解除。阳光刺破云层，洒在疲惫而羞愧的脸上。“天亮了，一切照旧。”有人低声说。小镇恢复了平静，店铺重新开张，炊烟袅袅升起。老陈回到他的修理铺，继续摆弄那些齿轮与发条。只是偶尔，他会停下手中的活计，望向窗外。那片曾被恐惧暂时统一的天空，如今又变回各自忙碌的背景。他修好了那座旧钟，指针重新走动的滴答声，轻轻叩击着恢复常态的寂静。昨日的疯狂已褪色成一个模糊的梦，而他从那场集体的迷航中，带回了一丝独属于自己的、关于“正常”的微妙疑问。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/f426c6fcb2ad/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/f426c6fcb2ad/" class="post-title-link" itemprop="url">微小说：石阶</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-12-11 09:33:41 / Modified: 09:35:42" itemprop="dateCreated datePublished" datetime="2025-12-11T09:33:41+08:00">2025-12-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>连绵阴雨浸透青石板路，老茶馆二楼临窗位置，男人指尖轻叩紫砂壶，注视檐水滴落。他每周三前来，只点同一款普洱，坐同一个位置。“做生意嘅，最紧要係和气生财。”他曾对挑衅的年轻人轻声说，推过一碟桃酥。</p>
<p>巷口修鞋匠总在日落前收摊，工具箱里藏着磨光的象牙算盘。某日暴雨倾盆，男人踏进水洼扶起脚滑的菜贩，捡拾滚落的番茄时，听见修鞋匠低语：“一个人行错一步，就翻唔到转头。”</p>
<p>午夜钟响，男人锁上茶馆木门，将账簿投入铁桶。火苗窜起时，他想起二十年前父亲临终的话：“江湖路，脚底下踩住几多骸骨。”晨光中，修鞋匠摊开旧报纸，豆腐干大小的公告报道着某商会改组。第一缕阳光掠过湿润的石阶，昨夜灰烬已被冲刷得不见痕迹。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/48a1c1800f0c/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/48a1c1800f0c/" class="post-title-link" itemprop="url">微小说：盲眼与心路</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-12-10 18:15:02 / Modified: 18:16:18" itemprop="dateCreated datePublished" datetime="2025-12-10T18:15:02+08:00">2025-12-10</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>山雾是白的，路是青的，陈老的石屋就嵌在山腰。他的眼睛三年前就盲了，世界缩成一片模糊的光晕。儿子为他装了能说话的电话，但他固执地摸着墙角那根磨得油亮的竹杖，“它认识路。”他说。</p>
<p>儿子不解，城里工作忙，只得托人送来一只据说极其聪明的导盲犬。狗很安静，鼻尖总是潮湿冰凉。第一天出门，陈老握着竹杖，狗缰绳松松的。“你带路？”他问狗。狗只是用头顶了顶他的手心。</p>
<p>他们沿着屋后小径走。竹杖叩击石板的哒哒声，是他的语言。他听见风过竹林的簌簌声，便知走到了老韩家的竹林；脚下泥土变得松软，带着腐叶气息，便是拐向溪桥。狗始终沉默跟随，在他脚步略微迟疑时，才会轻轻牵引。</p>
<p>他习惯了向狗絮叨。“这弯道旁有棵野柿树，秋日果子甜。”“前面坡陡，当年我背过摔伤的李家媳妇。”话语散在风里，像是说给山听。他感觉狗在听，那安静的呼吸便是一种回应。</p>
<p>一日，暴雨突至。他慌乱中踏滑，竹杖脱手。泥水裹挟着他，世界只剩下轰鸣。一个坚定的力量却顶住他腋下，是那只狗，奋力将他推向高处一块巨岩下。他浑身湿透，颤抖着手摸到狗湿漉漉的头。那一刻，他感到一种比视觉更确凿的温暖。雨停后，狗叼回了他的竹杖。</p>
<p>儿子再来看他，惊讶于父亲竟能独自走到更远的山涧。陈老抚着趴在一旁的狗，对儿子说：“它不认路，它认我。”儿子看见父亲空茫的眼中，有种他从未见过的光亮。山静静立着，路在脚下蜿蜒，通向云雾深处，也通向心底那片不再需要眼睛去看的清明。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/f0b46a31393b/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/f0b46a31393b/" class="post-title-link" itemprop="url">Hexo Next 主题添加 Google Adsense 和 Google Analytics 方法</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-12-10 00:00:00" itemprop="dateCreated datePublished" datetime="2025-12-10T00:00:00+08:00">2025-12-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-12-11 13:38:12" itemprop="dateModified" datetime="2025-12-11T13:38:12+08:00">2025-12-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h2><p>最近启动了一个新项目：<strong>电影台词AI文学创作系统</strong>。<br>该系统旨在将电影台词转化为AI文学创作的灵感源泉，通过以下三个核心模块实现：</p>
<ol>
<li><strong>字幕抓取与清洗</strong> → 获得纯净文本；</li>
<li><strong>台词分段与解析</strong> → 理解电影语境；</li>
<li><strong>AI识别与创作</strong> → 输出微小说。</li>
</ol>
<p>最终实现从影视语言到文学作品的智能转换。</p>
<p>项目内容逐渐丰富，便想到利用手头闲置的域名搭建展示页面，顺便记录一下 Hexo Next 主题添加 Google 服务的方法。</p>
<hr>
<h2 id="1-添加-Google-Analytics"><a href="#1-添加-Google-Analytics" class="headerlink" title="1. 添加 Google Analytics"></a>1. 添加 Google Analytics</h2><h4 id="环境信息"><a href="#环境信息" class="headerlink" title="环境信息"></a>环境信息</h4><ul>
<li>Hexo 版本：8.1.1  </li>
<li>主题：Next  </li>
<li>部署方式：本地部署</li>
</ul>
<h4 id="配置步骤"><a href="#配置步骤" class="headerlink" title="配置步骤"></a>配置步骤</h4><ol>
<li>将主题文件夹下的 <code>_config.yml</code> 复制到项目根目录，并重命名为 <code>_config.next.yml</code>。</li>
<li>在 <code>_config.next.yml</code> 中找到以下配置段：</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Google Analytics</span></span><br><span class="line"><span class="comment"># See: https://analytics.google.com</span></span><br><span class="line"><span class="attr">google_analytics:</span></span><br><span class="line">  <span class="attr">tracking_id:</span> <span class="string">G-WJ48W3LM1R</span></span><br><span class="line">  <span class="comment"># By default, NexT will load an external gtag.js script on your site.</span></span><br><span class="line">  <span class="comment"># If you only need the pageview feature, set the following option to true to get a better performance.</span></span><br></pre></td></tr></table></figure>
<p>将 tracking_id 替换为你自己的 Google Analytics 测量 ID（如 G-XXXXXXXXXX）。</p>
<p>无需手动插入 Google 提供的 JavaScript 代码，NexT 主题会自动加载 gtag.js。</p>
<h2 id="2-添加-Google-Adsense"><a href="#2-添加-Google-Adsense" class="headerlink" title="2. 添加 Google Adsense"></a>2. 添加 Google Adsense</h2><h4 id="步骤一：放置-ads-txt"><a href="#步骤一：放置-ads-txt" class="headerlink" title="步骤一：放置 ads.txt"></a>步骤一：放置 ads.txt</h4><p>在 Hexo 项目根目录的 source 文件夹下，新建 ads.txt 文件，内容粘贴 Google Adsense 提供的验证信息。</p>
<h4 id="步骤二：插入-Adsense-代码"><a href="#步骤二：插入-Adsense-代码" class="headerlink" title="步骤二：插入 Adsense 代码"></a>步骤二：插入 Adsense 代码</h4><p>打开主题布局文件：</p>
<p>next&#x2F;layout&#x2F;_partials&#x2F;head&#x2F;head.njk</p>
<p>在文件底部插入 Google Adsense 提供的 JavaScript 代码片段。</p>
<h2 id="3-生成与部署"><a href="#3-生成与部署" class="headerlink" title="3. 生成与部署"></a>3. 生成与部署</h2><p>配置完成后，在项目根目录执行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://let-ai.com/202512/3a23f75e6632/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="twoken">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI微小说">
      <meta itemprop="description" content="项目简介：本项目将电影台词转化为AI文学创作的灵感源泉。系统通过三个核心模块：1. 字幕抓取与清洗 → 获得纯净文本；2. 台词分段与解析 → 理解电影语境 ；3. AI识别与创作 → 输出微小说。实现从影视语言到文学作品的智能转换。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | AI微小说">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/202512/3a23f75e6632/" class="post-title-link" itemprop="url">在wsl下python3.10.16 torch2.4.0 cuda12.1 微调笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-12-06 00:00:00" itemprop="dateCreated datePublished" datetime="2025-12-06T00:00:00+08:00">2025-12-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-12-11 14:00:20" itemprop="dateModified" datetime="2025-12-11T14:00:20+08:00">2025-12-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="在wsl下python3-10-16-torch2-4-0-cuda12-1微调笔记"><a href="#在wsl下python3-10-16-torch2-4-0-cuda12-1微调笔记" class="headerlink" title="在wsl下python3.10.16 torch2.4.0 cuda12.1微调笔记"></a>在wsl下python3.10.16 torch2.4.0 cuda12.1微调笔记</h1><h2 id="0-屏蔽wsl中windows的环境变量"><a href="#0-屏蔽wsl中windows的环境变量" class="headerlink" title="0.屏蔽wsl中windows的环境变量"></a>0.屏蔽wsl中windows的环境变量</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#屏蔽wsl中的windows环境变量</span><br><span class="line">1.在wsl 的 ubuntu中编辑/etc/wsl.conf，输入：</span><br><span class="line"></span><br><span class="line">[interop]</span><br><span class="line">enabled = false</span><br><span class="line">appendWindowsPath = false</span><br><span class="line"></span><br><span class="line">退出保存之后，需要重启wsl。</span><br><span class="line">在cmd中，输入：</span><br><span class="line"></span><br><span class="line">wsl --shutdown</span><br></pre></td></tr></table></figure>

<h2 id="1-环境配置"><a href="#1-环境配置" class="headerlink" title="1.环境配置"></a>1.环境配置</h2><h5 id="1-1安装nvidia驱动，最新版即可"><a href="#1-1安装nvidia驱动，最新版即可" class="headerlink" title="1.1安装nvidia驱动，最新版即可"></a>1.1安装nvidia驱动，最新版即可</h5><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.nvidia.cn/geforce/drivers/">https://www.nvidia.cn/geforce/drivers/</a> ，选择自己的型号，这次安装了NVIDIA Studio 驱动程序 - WHQL</p>
<p>驱动程序版本: 572.60 - 发行日期: 2025-2-27</p>
</blockquote>
<p>安装后运行nvidia-smi，这里在windows下安装完，wsl中也可以执行</p>
<blockquote>
<p>(u2) zk@baize:~&#x2F;ai$ whereis nvidia-smi<br>nvidia-smi: &#x2F;usr&#x2F;bin&#x2F;nvidia-smi &#x2F;usr&#x2F;lib&#x2F;wsl&#x2F;lib&#x2F;nvidia-smi &#x2F;usr&#x2F;share&#x2F;man&#x2F;man1&#x2F;nvidia-smi.1.gz</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">(u2) zk@baize:~/ai$ nvidia-smi</span><br><span class="line">Wed Mar 12 10:53:45 2025</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 525.105.17   Driver Version: 572.60       CUDA Version: 12.8     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |</span><br><span class="line">| 41%   46C    P8    38W / 420W |   1003MiB / 24576MiB |      9%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br></pre></td></tr></table></figure>

<h5 id="1-2conda开虚拟环境"><a href="#1-2conda开虚拟环境" class="headerlink" title="1.2conda开虚拟环境"></a>1.2conda开虚拟环境</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda create --name u2 \</span><br><span class="line">	python=3.10 \</span><br><span class="line">	-y</span><br></pre></td></tr></table></figure>

<h5 id="1-3安装xformers-0-0-27-post1版本"><a href="#1-3安装xformers-0-0-27-post1版本" class="headerlink" title="1.3安装xformers 0.0.27.post1版本"></a>1.3安装xformers 0.0.27.post1版本</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U xformers==0.0.27.post1</span><br></pre></td></tr></table></figure>

<p>安装0.0.27.post1对应python310的torch版本为2.4.0，安装后cuda12.1也跟着装好了。</p>
<p>检查xformers情况</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">(u2) zk@baize:~/ai$ python -m xformers.info</span><br><span class="line">is_triton_available:                               True</span><br><span class="line">pytorch.version:                                   2.4.0+cu121</span><br><span class="line">pytorch.cuda:                                      available</span><br><span class="line">gpu.compute_capability:                            8.6</span><br><span class="line">gpu.name:                                          NVIDIA GeForce RTX 3090</span><br><span class="line">dcgm_profiler:                                     unavailable</span><br><span class="line">build.info:                                        available</span><br><span class="line">build.cuda_version:                                1201</span><br><span class="line">build.hip_version:                                 None</span><br><span class="line">build.python_version:                              3.10.14</span><br><span class="line">build.torch_version:                               2.4.0+cu121</span><br><span class="line">build.env.TORCH_CUDA_ARCH_LIST:                    6.0+PTX 7.0 7.5 8.0+PTX</span><br><span class="line">build.env.PYTORCH_ROCM_ARCH:                       None</span><br><span class="line">build.env.XFORMERS_BUILD_TYPE:                     Release</span><br><span class="line">build.env.XFORMERS_ENABLE_DEBUG_ASSERTIONS:        None</span><br><span class="line">build.env.NVCC_FLAGS:                              None</span><br><span class="line">build.env.XFORMERS_PACKAGE_FROM:                   wheel-v0.0.27.post1</span><br><span class="line">build.nvcc_version:                                12.1.66</span><br><span class="line">source.privacy:                                    open <span class="built_in">source</span></span><br></pre></td></tr></table></figure>

<p>这里可以看到pytorch.version: 2.4.0+cu121，build.torch_version: 2.4.0+cu121，这两个必须一致，前期安装好几次都不一致。</p>
<h5 id="1-4检查cuda安装，nvcc"><a href="#1-4检查cuda安装，nvcc" class="headerlink" title="1.4检查cuda安装，nvcc"></a>1.4检查cuda安装，nvcc</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(u2) zk@baize:~/ai$ nvcc -V</span><br><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2023 NVIDIA Corporation</span><br><span class="line">Built on Tue_Feb__7_19:32:13_PST_2023</span><br><span class="line">Cuda compilation tools, release 12.1, V12.1.66</span><br><span class="line">Build cuda_12.1.r12.1/compiler.32415258_0</span><br></pre></td></tr></table></figure>

<h5 id="1-5检查cuda激活"><a href="#1-5检查cuda激活" class="headerlink" title="1.5检查cuda激活"></a>1.5检查cuda激活</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">(u2) zk@baize:~/ai$ python</span><br><span class="line">Python 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0] on linux</span><br><span class="line">Type <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> or <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br><span class="line">&gt;&gt;&gt; import torch</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.__version__)</span><br><span class="line">2.4.0+cu121</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.cuda.is_available())</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.cuda.get_device_name(torch.cuda.current_device()))</span><br><span class="line">NVIDIA GeForce RTX 3090</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.cuda.device_count())</span><br><span class="line">1</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.cuda.get_device_properties(torch.cuda.current_device()))</span><br><span class="line">_CudaDeviceProperties(name=<span class="string">&#x27;NVIDIA GeForce RTX 3090&#x27;</span>, major=8, minor=6, total_memory=24575MB, multi_processor_count=82)</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.version.cuda)</span><br><span class="line">12.1</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.backends.cudnn.version())</span><br><span class="line">90100</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.cuda.get_arch_list())</span><br><span class="line">[<span class="string">&#x27;sm_50&#x27;</span>, <span class="string">&#x27;sm_60&#x27;</span>, <span class="string">&#x27;sm_70&#x27;</span>, <span class="string">&#x27;sm_75&#x27;</span>, <span class="string">&#x27;sm_80&#x27;</span>, <span class="string">&#x27;sm_86&#x27;</span>, <span class="string">&#x27;sm_90&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h5 id="1-6安装unsloth"><a href="#1-6安装unsloth" class="headerlink" title="1.6安装unsloth"></a>1.6安装unsloth</h5><p>unsloth官网example，根据cuda和torch版本选择</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">pip install &quot;unsloth[cu121-ampere-torch240] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br><span class="line">pip install &quot;unsloth[cu118-ampere-torch240] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br><span class="line">pip install &quot;unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br><span class="line">pip install &quot;unsloth[cu118-torch240] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br><span class="line"></span><br><span class="line">pip install &quot;unsloth[cu121-torch230] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br><span class="line">pip install &quot;unsloth[cu121-ampere-torch230] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br><span class="line"></span><br><span class="line">pip install &quot;unsloth[cu121-torch250] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br><span class="line">pip install &quot;unsloth[cu124-ampere-torch250] @ git+https://github.com/unslothai/unsloth.git&quot;</span><br></pre></td></tr></table></figure>

<p>这里要注意，有坑。找到pip install “unsloth[cu121-torch240] @ git+<a target="_blank" rel="noopener" href="https://github.com/unslothai/unsloth.git%22%E7%AC%A6%E5%90%88%E7%89%88%E6%9C%AC%EF%BC%8C%E4%B8%8B%E8%BD%BD%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%8F%91%E7%8E%B0%E4%BB%96%E5%8E%BB%E4%B8%8B%E8%BD%BDxformers-0.0.28.post1%EF%BC%8C%E8%BF%99%E4%BC%9A%E6%8A%8Atorch%E5%92%8Ccuda%E5%8F%88%E6%94%B9%E5%8F%98%E7%89%88%E6%9C%AC%EF%BC%8C%E9%9C%80%E8%A6%81%E5%8A%A0%E5%8F%82%E6%95%B0--no-deps">https://github.com/unslothai/unsloth.git&quot;符合版本，下载过程中发现他去下载xformers-0.0.28.post1，这会把torch和cuda又改变版本，需要加参数--no-deps</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install &quot;unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git&quot; --no-deps</span><br><span class="line">#这里安装完毕因为no deps没拉去了unsloth_zoo，应该加上unsloth_zoo</span><br></pre></td></tr></table></figure>

<p>安装unsloth所需其他依赖</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install --no-deps trl peft accelerate bitsandbytes</span><br><span class="line"></span><br><span class="line">pip install unsloth_zoo  #zoo不会改变torch和cuda版本</span><br></pre></td></tr></table></figure>

<h5 id="1-7预先编译好llama-cpp"><a href="#1-7预先编译好llama-cpp" class="headerlink" title="1.7预先编译好llama.cpp"></a>1.7预先编译好llama.cpp</h5><p>调用gpu编译llama.cpp</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#官方帮助文档：https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md</span><br><span class="line">cmake -B build -DGGML_CUDA=ON</span><br><span class="line">cmake --build build --config Release</span><br></pre></td></tr></table></figure>

<p>编译后，在&#x2F;home&#x2F;zk&#x2F;ai&#x2F;llama.cpp&#x2F;build&#x2F;bin下要有llama-quantize和llama-cli这两个主要文件。</p>
<h2 id="2-微调"><a href="#2-微调" class="headerlink" title="2.微调"></a>2.微调</h2><h5 id="2-1微调主代码"><a href="#2-1微调主代码" class="headerlink" title="2.1微调主代码"></a>2.1微调主代码</h5><p>这里把基础模型和数据集都改写成本地调用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> FastLanguageModel</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> SFTTrainer</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">max_seq_length = <span class="number">2048</span></span><br><span class="line">dtype = <span class="literal">None</span></span><br><span class="line">load_in_4bit = <span class="literal">True</span></span><br><span class="line">model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">    model_name = <span class="string">&quot;/home/zk/ai/base_model/llama-3-8b-bnb-4bit&quot;</span>,</span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    dtype = dtype,</span><br><span class="line">    load_in_4bit = load_in_4bit,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备训练数据</span></span><br><span class="line">alpaca_prompt = <span class="string">&quot;&quot;&quot;Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.</span></span><br><span class="line"><span class="string">### Instruction：</span></span><br><span class="line"><span class="string">&#123;&#125;</span></span><br><span class="line"><span class="string">### Input:</span></span><br><span class="line"><span class="string">&#123;&#125;</span></span><br><span class="line"><span class="string">### Response:</span></span><br><span class="line"><span class="string">&#123;&#125;&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">EOS_TOKEN = tokenizer.eos_token  <span class="comment"># 必须添加 EOS_TOKEN</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">formatting_prompts_func</span>(<span class="params">examples</span>):</span><br><span class="line">    instructions = examples[<span class="string">&quot;instruction&quot;</span>]</span><br><span class="line">    inputs = examples[<span class="string">&quot;input&quot;</span>]</span><br><span class="line">    outputs = examples[<span class="string">&quot;output&quot;</span>]</span><br><span class="line">    texts = []</span><br><span class="line">    <span class="keyword">for</span> instruction, <span class="built_in">input</span>, output <span class="keyword">in</span> <span class="built_in">zip</span>(instructions, inputs, outputs):</span><br><span class="line">        <span class="comment"># 必须添加EOS_TOKEN，否则无限生成</span></span><br><span class="line">        text = alpaca_prompt.<span class="built_in">format</span>(instruction, <span class="built_in">input</span>, output) + EOS_TOKEN</span><br><span class="line">        texts.append(text)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;text&quot;</span>: texts&#125;</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 本地数据集</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;json&quot;</span>, data_files = <span class="string">&quot;/home/zk/ai/dataset/caishui_2011_100hao.json&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(formatting_prompts_func, batched = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置训练参数</span></span><br><span class="line">model = FastLanguageModel.get_peft_model(</span><br><span class="line">    model,</span><br><span class="line">    r = <span class="number">16</span>,</span><br><span class="line">    target_modules = [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;k_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>, <span class="string">&quot;o_proj&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;gate_proj&quot;</span>, <span class="string">&quot;up_proj&quot;</span>, <span class="string">&quot;down_proj&quot;</span>, ],</span><br><span class="line">    lora_alpha = <span class="number">16</span>,</span><br><span class="line">    lora_dropout = <span class="number">0</span>,</span><br><span class="line">    bias = <span class="string">&quot;none&quot;</span>,</span><br><span class="line">    use_gradient_checkpointing = <span class="literal">True</span>,</span><br><span class="line">    random_state = <span class="number">3407</span>,</span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    use_rslora = <span class="literal">False</span>,</span><br><span class="line">    loftq_config = <span class="literal">None</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = SFTTrainer(</span><br><span class="line">    model = model,</span><br><span class="line">    train_dataset = dataset,</span><br><span class="line">    dataset_text_field = <span class="string">&quot;text&quot;</span>,</span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    tokenizer = tokenizer,</span><br><span class="line">    args = TrainingArguments(</span><br><span class="line">        per_device_train_batch_size = <span class="number">1</span>,</span><br><span class="line">        gradient_accumulation_steps = <span class="number">4</span>,</span><br><span class="line">        warmup_steps = <span class="number">2</span>,</span><br><span class="line">        max_steps = <span class="number">20</span>,</span><br><span class="line">        fp16 = <span class="keyword">not</span> torch.cuda.is_bf16_supported(),</span><br><span class="line">        bf16 = torch.cuda.is_bf16_supported(),</span><br><span class="line">        logging_steps = <span class="number">1</span>,</span><br><span class="line">        output_dir = <span class="string">&quot;outputs&quot;</span>,</span><br><span class="line">        optim = <span class="string">&quot;adamw_8bit&quot;</span>,</span><br><span class="line">        weight_decay = <span class="number">0.01</span>,</span><br><span class="line">        lr_scheduler_type = <span class="string">&quot;linear&quot;</span>,</span><br><span class="line">        seed = <span class="number">3407</span>,</span><br><span class="line">        learning_rate = <span class="number">2e-5</span>,</span><br><span class="line">    ),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line">trainer.train()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存微调模型</span></span><br><span class="line">model.save_pretrained(<span class="string">&quot;lora_model&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项：保存为16位hf模型</span></span><br><span class="line">save_16bit = <span class="built_in">input</span>(<span class="string">&quot;是否保存为16位hf模型？(y/n): &quot;</span>)</span><br><span class="line"><span class="keyword">if</span> save_16bit.lower() == <span class="string">&quot;y&quot;</span>:</span><br><span class="line">    model.save_pretrained_merged(<span class="string">&quot;outputs&quot;</span>, tokenizer, save_method=<span class="string">&quot;merged_16bit&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项：保存为gguf模型</span></span><br><span class="line">save_gguf = <span class="built_in">input</span>(<span class="string">&quot;是否保存为gguf模型？(y/n): &quot;</span>)</span><br><span class="line"><span class="keyword">if</span> save_gguf.lower() == <span class="string">&quot;y&quot;</span>:</span><br><span class="line">    os.system(<span class="string">&quot;python /home/zk/ai/llama.cpp/convert_hf_to_gguf.py --outfile /home/zk/ai/gguf_model/lm38b_tax_jzjt.gguf /home/zk/ai/outputs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项：量化为4位gguf模型</span></span><br><span class="line">quantize_4bit = <span class="built_in">input</span>(<span class="string">&quot;是否量化为4位gguf模型？(y/n): &quot;</span>)</span><br><span class="line"><span class="keyword">if</span> quantize_4bit.lower() == <span class="string">&quot;y&quot;</span>:</span><br><span class="line">    os.system(<span class="string">&quot;/home/zk/ai/llama.cpp/build/bin/llama-quantize /home/zk/ai/gguf_model/QWQ_tax_jzjt.gguf /home/zk/ai/gguf_model/lm38b_tax_jzjt-Q4_K_M.gguf Q4_K_M&quot;</span>)</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">twoken</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
